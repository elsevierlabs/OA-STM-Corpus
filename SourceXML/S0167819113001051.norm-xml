<?xml version="1.0" encoding="UTF-8"?><!-- Normalized for easier text mining. --><xocs:doc xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.elsevier.com/xml/ja/dtd" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://schema.elsevier.com/dtds/document/fulltext/xcr/xocs-article.xsd"><xocs:meta><xocs:content-family>serial</xocs:content-family><xocs:content-type>JL</xocs:content-type><xocs:cid>271636</xocs:cid><xocs:srctitle>Parallel Computing</xocs:srctitle><xocs:normalized-srctitle>PARALLELCOMPUTING</xocs:normalized-srctitle><xocs:orig-load-date>2013-09-13</xocs:orig-load-date><xocs:ew-transaction-id>2013-11-19T20:46:19</xocs:ew-transaction-id><xocs:eid>1-s2.0-S0167819113001051</xocs:eid><xocs:pii-formatted>S0167-8191(13)00105-1</xocs:pii-formatted><xocs:pii-unformatted>S0167819113001051</xocs:pii-unformatted><xocs:doi>10.1016/j.parco.2013.09.001</xocs:doi><xocs:item-stage>S300</xocs:item-stage><xocs:item-version-number>S300.1</xocs:item-version-number><xocs:item-weight>FULL-TEXT</xocs:item-weight><xocs:hub-eid>1-s2.0-S0167819113X00092</xocs:hub-eid><xocs:timestamp>2014-02-03T15:49:17.385808-05:00</xocs:timestamp><xocs:issns><xocs:issn-primary-formatted>0167-8191</xocs:issn-primary-formatted><xocs:issn-primary-unformatted>01678191</xocs:issn-primary-unformatted></xocs:issns><xocs:sponsored-access-type>UNLIMITED</xocs:sponsored-access-type><xocs:funding-body-id>EPSRCPP</xocs:funding-body-id><xocs:crossmark>true</xocs:crossmark><xocs:vol-first>39</xocs:vol-first><xocs:iss-first>11</xocs:iss-first><xocs:vol-iss-suppl-text>Volume 39, Issue 11</xocs:vol-iss-suppl-text><xocs:sort-order>4</xocs:sort-order><xocs:first-fp>693</xocs:first-fp><xocs:last-lp>708</xocs:last-lp><xocs:pages><xocs:first-page>693</xocs:first-page><xocs:last-page>708</xocs:last-page></xocs:pages><xocs:cover-date-orig><xocs:start-date>201311</xocs:start-date></xocs:cover-date-orig><xocs:cover-date-text>November 2013</xocs:cover-date-text><xocs:cover-date-start>2013-11-01</xocs:cover-date-start><xocs:cover-date-end>2013-11-30</xocs:cover-date-end><xocs:cover-date-year>2013</xocs:cover-date-year><xocs:document-type>article</xocs:document-type><xocs:document-subtype>fla</xocs:document-subtype><xocs:copyright-line>Copyright © 2013 The Authors. Published by Elsevier B.V. All rights reserved.</xocs:copyright-line><xocs:normalized-article-title>SPINNAKERFAULTTOLERANCEINAPOWERAREACONSTRAINEDLARGESCALENEUROMIMETICARCHITECTURE</xocs:normalized-article-title><xocs:normalized-first-auth-surname>NAVARIDAS</xocs:normalized-first-auth-surname><xocs:normalized-first-auth-initial>J</xocs:normalized-first-auth-initial><xocs:item-toc><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>1</xocs:item-toc-label><xocs:item-toc-section-title>Introduction</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>2</xocs:item-toc-label><xocs:item-toc-section-title>Background</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3</xocs:item-toc-label><xocs:item-toc-section-title>Overview of SpiNNaker</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.1</xocs:item-toc-label><xocs:item-toc-section-title>Application-induced architecture</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.2</xocs:item-toc-label><xocs:item-toc-section-title>SpiNNaker chip</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4</xocs:item-toc-label><xocs:item-toc-section-title>Fault tolerant architecture</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>5</xocs:item-toc-label><xocs:item-toc-section-title>Diagnostics and dynamic configuration</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>5.1</xocs:item-toc-label><xocs:item-toc-section-title>Power-on diagnostics and configuration</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>5.1.1</xocs:item-toc-label><xocs:item-toc-section-title>Evaluation of flood filling policies</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>5.2</xocs:item-toc-label><xocs:item-toc-section-title>Run-time reconfiguration</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6</xocs:item-toc-label><xocs:item-toc-section-title>Communications fault tolerance</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6.1</xocs:item-toc-label><xocs:item-toc-section-title>On-chip and off-chip communication</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6.2</xocs:item-toc-label><xocs:item-toc-section-title>Topological robustness</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6.3</xocs:item-toc-label><xocs:item-toc-section-title>Interconnect stability under severe degradation</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6.3.1</xocs:item-toc-label><xocs:item-toc-section-title>Simulation model of the SpiNNaker network</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6.3.2</xocs:item-toc-label><xocs:item-toc-section-title>Experiments and discussion of results</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6.4</xocs:item-toc-label><xocs:item-toc-section-title>Chip-to-chip interfaces</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6.4.1</xocs:item-toc-label><xocs:item-toc-section-title>Performance assessment</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6.5</xocs:item-toc-label><xocs:item-toc-section-title>Intra-chip connections</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>7</xocs:item-toc-label><xocs:item-toc-section-title>Other fault-tolerant features</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>7.1</xocs:item-toc-label><xocs:item-toc-section-title>Clock redundancy</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>7.2</xocs:item-toc-label><xocs:item-toc-section-title>GALS implications on fault tolerance</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>7.3</xocs:item-toc-label><xocs:item-toc-section-title>Memory subsystem fault tolerance</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>7.4</xocs:item-toc-label><xocs:item-toc-section-title>Connecting with the outside world</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>8</xocs:item-toc-label><xocs:item-toc-section-title>Related work</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>9</xocs:item-toc-label><xocs:item-toc-section-title>Summary and conclusions</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:acknowledgment"><xocs:item-toc-section-title>Acknowledgements</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:bibliography"><xocs:item-toc-section-title>References</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc><xocs:references><xocs:ref-info refid="j0005"/><xocs:ref-info refid="h0005"><xocs:ref-normalized-surname>ELLIOTT</xocs:ref-normalized-surname><xocs:ref-pub-year>2003</xocs:ref-pub-year><xocs:ref-first-fp>2187</xocs:ref-first-fp><xocs:ref-last-lp>2206</xocs:ref-last-lp><xocs:ref-normalized-initial>T</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0010"/><xocs:ref-info refid="j0015"/><xocs:ref-info refid="h0010"><xocs:ref-normalized-surname>CONSTANTINESCU</xocs:ref-normalized-surname><xocs:ref-pub-year>2003</xocs:ref-pub-year><xocs:ref-first-fp>14</xocs:ref-first-fp><xocs:ref-last-lp>19</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0020"/><xocs:ref-info refid="h0015"><xocs:ref-normalized-surname>IZHIKEVICH</xocs:ref-normalized-surname><xocs:ref-pub-year>2003</xocs:ref-pub-year><xocs:ref-first-fp>1569</xocs:ref-first-fp><xocs:ref-last-lp>1572</xocs:ref-last-lp><xocs:ref-normalized-initial>E</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0025"/><xocs:ref-info refid="h0020"><xocs:ref-normalized-surname>RAST</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>553</xocs:ref-first-fp><xocs:ref-last-lp>582</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="h0025"><xocs:ref-normalized-surname>ROSENBLATT</xocs:ref-normalized-surname><xocs:ref-pub-year>1962</xocs:ref-pub-year><xocs:ref-normalized-initial>F</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PRINCIPLESNEURODYNAMICSPERCEPTRONSTHEORYBRAINMECHANISMS</xocs:ref-normalized-srctitle></xocs:ref-info><xocs:ref-info refid="j0030"/><xocs:ref-info refid="h0030"><xocs:ref-normalized-surname>TIESINGA</xocs:ref-normalized-surname><xocs:ref-pub-year>2001</xocs:ref-pub-year><xocs:ref-first-fp>215</xocs:ref-first-fp><xocs:ref-last-lp>233</xocs:ref-last-lp><xocs:ref-normalized-initial>P</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="h0035"><xocs:ref-normalized-surname>BRODY</xocs:ref-normalized-surname><xocs:ref-pub-year>1978</xocs:ref-pub-year><xocs:ref-first-fp>345</xocs:ref-first-fp><xocs:ref-last-lp>351</xocs:ref-last-lp><xocs:ref-normalized-initial>H</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0035"/><xocs:ref-info refid="j0040"/><xocs:ref-info refid="j0045"/><xocs:ref-info refid="j0050"/><xocs:ref-info refid="j0055"/><xocs:ref-info refid="h0040"><xocs:ref-normalized-surname>NAVARIDAS</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>494</xocs:ref-first-fp><xocs:ref-last-lp>515</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0060"/><xocs:ref-info refid="j0065"/><xocs:ref-info refid="h0045"><xocs:ref-normalized-surname>VERHOEFF</xocs:ref-normalized-surname><xocs:ref-pub-year>1988</xocs:ref-pub-year><xocs:ref-first-fp>1</xocs:ref-first-fp><xocs:ref-last-lp>8</xocs:ref-last-lp><xocs:ref-normalized-initial>T</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="h0050"><xocs:ref-normalized-surname>BAINBRIDGE</xocs:ref-normalized-surname><xocs:ref-pub-year>2002</xocs:ref-pub-year><xocs:ref-first-fp>16</xocs:ref-first-fp><xocs:ref-last-lp>23</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0070"/><xocs:ref-info refid="j0075"/><xocs:ref-info refid="j0080"/><xocs:ref-info refid="j0085"/><xocs:ref-info refid="j0090"/><xocs:ref-info refid="j0095"/><xocs:ref-info refid="j0100"/><xocs:ref-info refid="h0055"><xocs:ref-normalized-surname>HAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>1</xocs:ref-first-fp><xocs:ref-last-lp>8</xocs:ref-last-lp><xocs:ref-normalized-initial>B</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="h0060"><xocs:ref-normalized-surname>BHUIYAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>1</xocs:ref-first-fp><xocs:ref-last-lp>8</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="h0065"><xocs:ref-normalized-surname>MARKRAM</xocs:ref-normalized-surname><xocs:ref-pub-year>2006</xocs:ref-pub-year><xocs:ref-first-fp>153</xocs:ref-first-fp><xocs:ref-last-lp>160</xocs:ref-last-lp><xocs:ref-normalized-initial>H</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0105"/><xocs:ref-info refid="j0110"/><xocs:ref-info refid="h0070"><xocs:ref-normalized-surname>HARING</xocs:ref-normalized-surname><xocs:ref-pub-year>2005</xocs:ref-pub-year><xocs:ref-first-fp>289</xocs:ref-first-fp><xocs:ref-last-lp>301</xocs:ref-last-lp><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0115"/><xocs:ref-info refid="j0120"/><xocs:ref-info refid="j0125"/><xocs:ref-info refid="j0130"/><xocs:ref-info refid="h0075"><xocs:ref-normalized-surname>OBERMAISSER</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year><xocs:ref-first-fp>123</xocs:ref-first-fp><xocs:ref-last-lp>134</xocs:ref-last-lp><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="h0080"><xocs:ref-normalized-surname>MAHMUD</xocs:ref-normalized-surname><xocs:ref-pub-year>2002</xocs:ref-pub-year><xocs:ref-first-fp>147</xocs:ref-first-fp><xocs:ref-last-lp>161</xocs:ref-last-lp><xocs:ref-normalized-initial>S</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0135"/><xocs:ref-info refid="h0085"><xocs:ref-normalized-surname>CHEN</xocs:ref-normalized-surname><xocs:ref-pub-year>1999</xocs:ref-pub-year><xocs:ref-first-fp>386</xocs:ref-first-fp><xocs:ref-last-lp>397</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="h0090"><xocs:ref-normalized-surname>HONG</xocs:ref-normalized-surname><xocs:ref-pub-year>2004</xocs:ref-pub-year><xocs:ref-first-fp>93</xocs:ref-first-fp><xocs:ref-last-lp>101</xocs:ref-last-lp><xocs:ref-normalized-initial>I</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="j0140"/><xocs:ref-info refid="h0095"><xocs:ref-normalized-surname>GOMEZ</xocs:ref-normalized-surname><xocs:ref-pub-year>2006</xocs:ref-pub-year><xocs:ref-first-fp>400</xocs:ref-first-fp><xocs:ref-last-lp>415</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="h0100"><xocs:ref-normalized-surname>PUENTE</xocs:ref-normalized-surname><xocs:ref-pub-year>2007</xocs:ref-pub-year><xocs:ref-first-fp>776</xocs:ref-first-fp><xocs:ref-last-lp>788</xocs:ref-last-lp><xocs:ref-normalized-initial>V</xocs:ref-normalized-initial></xocs:ref-info></xocs:references><xocs:attachment-metadata-doc><xocs:attachment-set-type>item</xocs:attachment-set-type><xocs:pii-formatted>S0167-8191(13)00105-1</xocs:pii-formatted><xocs:pii-unformatted>S0167819113001051</xocs:pii-unformatted><xocs:eid>1-s2.0-S0167819113001051</xocs:eid><xocs:doi>10.1016/j.parco.2013.09.001</xocs:doi><xocs:cid>271636</xocs:cid><xocs:timestamp>2013-11-19T17:33:11.542031-05:00</xocs:timestamp><xocs:path>/271636/1-s2.0-S0167819113X00092/1-s2.0-S0167819113001051/</xocs:path><xocs:cover-date-start>2013-11-01</xocs:cover-date-start><xocs:cover-date-end>2013-11-30</xocs:cover-date-end><xocs:sponsored-access-type>UNLIMITED</xocs:sponsored-access-type><xocs:funding-body-id>EPSRCPP</xocs:funding-body-id><xocs:attachments><xocs:web-pdf><xocs:attachment-eid>1-s2.0-S0167819113001051-main.pdf</xocs:attachment-eid><xocs:filename>main.pdf</xocs:filename><xocs:extension>pdf</xocs:extension><xocs:pdf-optimized>true</xocs:pdf-optimized><xocs:filesize>2448376</xocs:filesize><xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose><xocs:web-pdf-page-count>16</xocs:web-pdf-page-count><xocs:web-pdf-images><xocs:web-pdf-image><xocs:attachment-eid>1-s2.0-S0167819113001051-main_1.png</xocs:attachment-eid><xocs:filename>main_1.png</xocs:filename><xocs:extension>png</xocs:extension><xocs:filesize>112362</xocs:filesize><xocs:pixel-height>849</xocs:pixel-height><xocs:pixel-width>656</xocs:pixel-width><xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type><xocs:pdf-page-num>1</xocs:pdf-page-num></xocs:web-pdf-image></xocs:web-pdf-images></xocs:web-pdf><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si9.gif</xocs:attachment-eid><xocs:file-basename>si9</xocs:file-basename><xocs:filename>si9.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>482</xocs:filesize><xocs:pixel-height>14</xocs:pixel-height><xocs:pixel-width>79</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si8.gif</xocs:attachment-eid><xocs:file-basename>si8</xocs:file-basename><xocs:filename>si8.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>282</xocs:filesize><xocs:pixel-height>18</xocs:pixel-height><xocs:pixel-width>29</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si7.gif</xocs:attachment-eid><xocs:file-basename>si7</xocs:file-basename><xocs:filename>si7.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>338</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>38</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si6.gif</xocs:attachment-eid><xocs:file-basename>si6</xocs:file-basename><xocs:filename>si6.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>271</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>26</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si5.gif</xocs:attachment-eid><xocs:file-basename>si5</xocs:file-basename><xocs:filename>si5.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>278</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>26</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si4.gif</xocs:attachment-eid><xocs:file-basename>si4</xocs:file-basename><xocs:filename>si4.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>224</xocs:filesize><xocs:pixel-height>13</xocs:pixel-height><xocs:pixel-width>22</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si3.gif</xocs:attachment-eid><xocs:file-basename>si3</xocs:file-basename><xocs:filename>si3.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>280</xocs:filesize><xocs:pixel-height>14</xocs:pixel-height><xocs:pixel-width>31</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si2.gif</xocs:attachment-eid><xocs:file-basename>si2</xocs:file-basename><xocs:filename>si2.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>280</xocs:filesize><xocs:pixel-height>14</xocs:pixel-height><xocs:pixel-width>31</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si18.gif</xocs:attachment-eid><xocs:file-basename>si18</xocs:file-basename><xocs:filename>si18.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>293</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>32</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si17.gif</xocs:attachment-eid><xocs:file-basename>si17</xocs:file-basename><xocs:filename>si17.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>278</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>26</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si16.gif</xocs:attachment-eid><xocs:file-basename>si16</xocs:file-basename><xocs:filename>si16.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>278</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>26</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si15.gif</xocs:attachment-eid><xocs:file-basename>si15</xocs:file-basename><xocs:filename>si15.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>282</xocs:filesize><xocs:pixel-height>18</xocs:pixel-height><xocs:pixel-width>29</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si14.gif</xocs:attachment-eid><xocs:file-basename>si14</xocs:file-basename><xocs:filename>si14.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>482</xocs:filesize><xocs:pixel-height>14</xocs:pixel-height><xocs:pixel-width>79</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si13.gif</xocs:attachment-eid><xocs:file-basename>si13</xocs:file-basename><xocs:filename>si13.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>282</xocs:filesize><xocs:pixel-height>18</xocs:pixel-height><xocs:pixel-width>29</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si12.gif</xocs:attachment-eid><xocs:file-basename>si12</xocs:file-basename><xocs:filename>si12.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>266</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>26</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si11.gif</xocs:attachment-eid><xocs:file-basename>si11</xocs:file-basename><xocs:filename>si11.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>266</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>26</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si10.gif</xocs:attachment-eid><xocs:file-basename>si10</xocs:file-basename><xocs:filename>si10.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>503</xocs:filesize><xocs:pixel-height>14</xocs:pixel-height><xocs:pixel-width>99</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-si1.gif</xocs:attachment-eid><xocs:file-basename>si1</xocs:file-basename><xocs:filename>si1.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>482</xocs:filesize><xocs:pixel-height>14</xocs:pixel-height><xocs:pixel-width>79</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr1.jpg</xocs:attachment-eid><xocs:file-basename>gr1</xocs:file-basename><xocs:filename>gr1.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>46126</xocs:filesize><xocs:pixel-height>236</xocs:pixel-height><xocs:pixel-width>533</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr9.jpg</xocs:attachment-eid><xocs:file-basename>gr9</xocs:file-basename><xocs:filename>gr9.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>12978</xocs:filesize><xocs:pixel-height>267</xocs:pixel-height><xocs:pixel-width>378</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr8.jpg</xocs:attachment-eid><xocs:file-basename>gr8</xocs:file-basename><xocs:filename>gr8.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>11283</xocs:filesize><xocs:pixel-height>88</xocs:pixel-height><xocs:pixel-width>378</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr7.jpg</xocs:attachment-eid><xocs:file-basename>gr7</xocs:file-basename><xocs:filename>gr7.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>56782</xocs:filesize><xocs:pixel-height>204</xocs:pixel-height><xocs:pixel-width>578</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr6.jpg</xocs:attachment-eid><xocs:file-basename>gr6</xocs:file-basename><xocs:filename>gr6.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>52393</xocs:filesize><xocs:pixel-height>481</xocs:pixel-height><xocs:pixel-width>664</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr5.jpg</xocs:attachment-eid><xocs:file-basename>gr5</xocs:file-basename><xocs:filename>gr5.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>51871</xocs:filesize><xocs:pixel-height>451</xocs:pixel-height><xocs:pixel-width>489</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr4.jpg</xocs:attachment-eid><xocs:file-basename>gr4</xocs:file-basename><xocs:filename>gr4.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>52958</xocs:filesize><xocs:pixel-height>254</xocs:pixel-height><xocs:pixel-width>667</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr3.jpg</xocs:attachment-eid><xocs:file-basename>gr3</xocs:file-basename><xocs:filename>gr3.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>101707</xocs:filesize><xocs:pixel-height>425</xocs:pixel-height><xocs:pixel-width>671</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr2.jpg</xocs:attachment-eid><xocs:file-basename>gr2</xocs:file-basename><xocs:filename>gr2.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>46752</xocs:filesize><xocs:pixel-height>185</xocs:pixel-height><xocs:pixel-width>533</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr13.jpg</xocs:attachment-eid><xocs:file-basename>gr13</xocs:file-basename><xocs:filename>gr13.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>18158</xocs:filesize><xocs:pixel-height>319</xocs:pixel-height><xocs:pixel-width>353</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr12.jpg</xocs:attachment-eid><xocs:file-basename>gr12</xocs:file-basename><xocs:filename>gr12.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>10825</xocs:filesize><xocs:pixel-height>145</xocs:pixel-height><xocs:pixel-width>311</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr11.jpg</xocs:attachment-eid><xocs:file-basename>gr11</xocs:file-basename><xocs:filename>gr11.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>15959</xocs:filesize><xocs:pixel-height>150</xocs:pixel-height><xocs:pixel-width>311</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr10.jpg</xocs:attachment-eid><xocs:file-basename>gr10</xocs:file-basename><xocs:filename>gr10.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>48875</xocs:filesize><xocs:pixel-height>379</xocs:pixel-height><xocs:pixel-width>489</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr1.sml</xocs:attachment-eid><xocs:file-basename>gr1</xocs:file-basename><xocs:filename>gr1.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>4598</xocs:filesize><xocs:pixel-height>97</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr9.sml</xocs:attachment-eid><xocs:file-basename>gr9</xocs:file-basename><xocs:filename>gr9.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>3440</xocs:filesize><xocs:pixel-height>155</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr8.sml</xocs:attachment-eid><xocs:file-basename>gr8</xocs:file-basename><xocs:filename>gr8.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>3474</xocs:filesize><xocs:pixel-height>51</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr7.sml</xocs:attachment-eid><xocs:file-basename>gr7</xocs:file-basename><xocs:filename>gr7.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>5976</xocs:filesize><xocs:pixel-height>77</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr6.sml</xocs:attachment-eid><xocs:file-basename>gr6</xocs:file-basename><xocs:filename>gr6.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>4914</xocs:filesize><xocs:pixel-height>159</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr5.sml</xocs:attachment-eid><xocs:file-basename>gr5</xocs:file-basename><xocs:filename>gr5.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>5977</xocs:filesize><xocs:pixel-height>163</xocs:pixel-height><xocs:pixel-width>177</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr4.sml</xocs:attachment-eid><xocs:file-basename>gr4</xocs:file-basename><xocs:filename>gr4.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>7440</xocs:filesize><xocs:pixel-height>83</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr3.sml</xocs:attachment-eid><xocs:file-basename>gr3</xocs:file-basename><xocs:filename>gr3.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>10368</xocs:filesize><xocs:pixel-height>139</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr2.sml</xocs:attachment-eid><xocs:file-basename>gr2</xocs:file-basename><xocs:filename>gr2.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>9299</xocs:filesize><xocs:pixel-height>76</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr13.sml</xocs:attachment-eid><xocs:file-basename>gr13</xocs:file-basename><xocs:filename>gr13.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>2506</xocs:filesize><xocs:pixel-height>164</xocs:pixel-height><xocs:pixel-width>181</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr12.sml</xocs:attachment-eid><xocs:file-basename>gr12</xocs:file-basename><xocs:filename>gr12.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>1798</xocs:filesize><xocs:pixel-height>102</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr11.sml</xocs:attachment-eid><xocs:file-basename>gr11</xocs:file-basename><xocs:filename>gr11.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>3003</xocs:filesize><xocs:pixel-height>106</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0167819113001051-gr10.sml</xocs:attachment-eid><xocs:file-basename>gr10</xocs:file-basename><xocs:filename>gr10.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>5337</xocs:filesize><xocs:pixel-height>164</xocs:pixel-height><xocs:pixel-width>211</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment></xocs:attachments></xocs:attachment-metadata-doc><xocs:refkeys><xocs:refkey3>NAVARIDASX2013X693</xocs:refkey3><xocs:refkey4lp>NAVARIDASX2013X693X708</xocs:refkey4lp><xocs:refkey4ai>NAVARIDASX2013X693XJ</xocs:refkey4ai><xocs:refkey5>NAVARIDASX2013X693X708XJ</xocs:refkey5></xocs:refkeys><xocs:open-access><xocs:oa-article-status is-open-access="1" is-open-archive="0">Full</xocs:oa-article-status><xocs:oa-access-effective-date>2013-09-06T10:19:59Z</xocs:oa-access-effective-date><xocs:oa-sponsor><xocs:oa-sponsor-type>FundingBody</xocs:oa-sponsor-type><xocs:oa-sponsor-name>Engineering and Physical Sciences Research Council</xocs:oa-sponsor-name></xocs:oa-sponsor><xocs:oa-user-license>http://creativecommons.org/licenses/by/3.0/</xocs:oa-user-license></xocs:open-access></xocs:meta><xocs:serial-item><article xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" docsubtype="fla" xml:lang="en" version="5.2"><item-info><jid>PARCO</jid><aid>2141</aid><ce:pii>S0167-8191(13)00105-1</ce:pii><ce:doi>10.1016/j.parco.2013.09.001</ce:doi><ce:copyright type="other" year="2013">The Authors</ce:copyright></item-info><ce:floats><ce:figure id="f0005"><ce:label>Fig. 1</ce:label><ce:caption id="cn005"><ce:simple-para id="sp015" view="all">Overall view of SpiNNaker.</ce:simple-para></ce:caption><ce:link locator="gr1"/></ce:figure><ce:figure id="f0010"><ce:label>Fig. 2</ce:label><ce:caption id="cn010"><ce:simple-para id="sp020" view="all">SpiNNaker chip and boards.</ce:simple-para></ce:caption><ce:link locator="gr2"/></ce:figure><ce:figure id="f0015"><ce:label>Fig. 3</ce:label><ce:caption id="cn015"><ce:simple-para id="sp025" view="all">User Interface showing the status of the chips in a 48-chip board. The hexagonal shape represents the actual connection of the chips in a 48-chip board.</ce:simple-para></ce:caption><ce:link locator="gr3"/></ce:figure><ce:figure id="f0020"><ce:label>Fig. 4</ce:label><ce:caption id="cn020"><ce:simple-para id="sp030" view="all">Architecture of a SpiNNaker chip.</ce:simple-para></ce:caption><ce:link locator="gr4"/></ce:figure><ce:figure id="f0025"><ce:label>Fig. 5</ce:label><ce:caption id="cn025"><ce:simple-para id="sp035" view="all">Map of fault-tolerant features.</ce:simple-para></ce:caption><ce:link locator="gr5"/></ce:figure><ce:figure id="f0030"><ce:label>Fig. 6</ce:label><ce:caption id="cn030"><ce:simple-para id="sp040" view="all">Results of simulating the application loading process.</ce:simple-para></ce:caption><ce:link locator="gr6"/></ce:figure><ce:figure id="f0035"><ce:label>Fig. 7</ce:label><ce:caption id="cn035"><ce:simple-para id="sp045" view="all">Examples of the cuts used in this experimental work. Diagonal links are not cut, so the network is not completely split.</ce:simple-para></ce:caption><ce:link locator="gr7"/></ce:figure><ce:figure id="f0040"><ce:label>Fig. 8</ce:label><ce:caption id="cn040"><ce:simple-para id="sp050" view="all">Regular (direct) and emergency routes from a chip to a neighbour.</ce:simple-para></ce:caption><ce:link locator="gr8"/></ce:figure><ce:figure id="f0045"><ce:label>Fig. 9</ce:label><ce:caption id="cn045"><ce:simple-para id="sp055" view="all">Number of disconnected nodes in the presence of link failures of 2<ce:sup loc="post">16</ce:sup>-node topologies.</ce:simple-para></ce:caption><ce:link locator="gr9"/></ce:figure><ce:figure id="f0050"><ce:label>Fig. 10</ce:label><ce:caption id="cn050"><ce:simple-para id="sp060" view="all">Temporal evolution of accepted load, latency figures and dropped packets for a <mml:math altimg="si1.gif" overflow="scroll"><mml:mrow><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:math> gradually degrading SpiNNaker system.</ce:simple-para></ce:caption><ce:link locator="gr10"/></ce:figure><ce:figure id="f0055"><ce:label>Fig. 11</ce:label><ce:caption id="cn055"><ce:simple-para id="sp065" view="all">Inter-Chip link receiver.</ce:simple-para></ce:caption><ce:link locator="gr11"/></ce:figure><ce:figure id="f0060"><ce:label>Fig. 12</ce:label><ce:caption id="cn060"><ce:simple-para id="sp070" view="all">Phase-Insensitive NRZ-RTZ converter.</ce:simple-para></ce:caption><ce:link locator="gr12"/></ce:figure><ce:figure id="f0065"><ce:label>Fig. 13</ce:label><ce:caption id="cn065"><ce:simple-para id="sp075" view="all">Fault-tolerant symbol converter.</ce:simple-para></ce:caption><ce:link locator="gr13"/></ce:figure><ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" frame="topbot" id="t0005" rowsep="0" colsep="0"><ce:label>Table 1</ce:label><ce:caption id="cn070"><ce:simple-para id="sp080" view="all">Relative area of the different components within a SpiNNaker chip. See <ce:cross-ref id="c0330" refid="f0020">Fig. 4</ce:cross-ref>(a) for the actual overlay.</ce:simple-para></ce:caption><tgroup cols="2"><colspec colname="col1" align="left"/><colspec colname="col2" align="left"/><thead><row rowsep="1" valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Component</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Relative area (%)</entry></row></thead><tbody><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Tightly coupled memories (<mml:math altimg="si2.gif" overflow="scroll"><mml:mrow><mml:mo>×</mml:mo><mml:mn>18</mml:mn></mml:mrow></mml:math>)</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">50</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">ARM cores (<mml:math altimg="si3.gif" overflow="scroll"><mml:mrow><mml:mo>×</mml:mo><mml:mn>18</mml:mn></mml:mrow></mml:math>)</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">29</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">System NOC</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">11</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Router</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">6.7</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">System SRAM memory</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">0.96</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">SDRAM interface</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">0.75</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Phase-locked loops (<mml:math altimg="si4.gif" overflow="scroll"><mml:mrow><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math>)</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">0.67</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Ethernet interface</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">0.65</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">ROM memory</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">0.25</entry></row></tbody></tgroup></ce:table><ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" frame="topbot" id="t0010" rowsep="0" colsep="0"><ce:label>Table 2</ce:label><ce:caption id="cn075"><ce:simple-para id="sp085" view="all">Simulation results for chip-to-chip interface designs.</ce:simple-para></ce:caption><tgroup cols="3"><colspec colname="col1" align="left"/><colspec colname="col2" align="left"/><colspec colname="col3" align="left"/><thead><row rowsep="1" valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Protocol converter</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Conventional (%)</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Fault-tolerant (%)</entry></row></thead><tbody><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Glitches</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">47.98</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">48.54</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Error-free packets</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">91.97</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">82.96</entry></row><row valign="top"><entry xmlns="http://www.elsevier.com/xml/common/dtd">Deadlocks</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">1.60</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">0.00</entry></row></tbody></tgroup></ce:table></ce:floats><head><ce:article-footnote><ce:label>☆</ce:label><ce:note-para id="np005" view="all">This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</ce:note-para></ce:article-footnote><ce:title id="tm005">SpiNNaker: Fault tolerance in a power- and area- constrained large-scale neuromimetic architecture</ce:title><ce:author-group id="ag005"><ce:author id="au005"><ce:given-name>Javier</ce:given-name><ce:surname>Navaridas</ce:surname><ce:cross-ref id="ar005" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref><ce:cross-ref id="ar010" refid="cor1"><ce:sup loc="post">⁎</ce:sup></ce:cross-ref><ce:e-address id="em005" type="email">javier.navaridas@manchester.ac.uk</ce:e-address></ce:author><ce:author id="au010"><ce:given-name>Steve</ce:given-name><ce:surname>Furber</ce:surname><ce:cross-ref id="ar015" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au015"><ce:given-name>Jim</ce:given-name><ce:surname>Garside</ce:surname><ce:cross-ref id="ar020" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au020"><ce:given-name>Xin</ce:given-name><ce:surname>Jin</ce:surname><ce:cross-ref id="ar025" refid="af010"><ce:sup loc="post">b</ce:sup></ce:cross-ref></ce:author><ce:author id="au025"><ce:given-name>Mukaram</ce:given-name><ce:surname>Khan</ce:surname><ce:cross-ref id="ar030" refid="af015"><ce:sup loc="post">c</ce:sup></ce:cross-ref></ce:author><ce:author id="au030"><ce:given-name>David</ce:given-name><ce:surname>Lester</ce:surname><ce:cross-ref id="ar035" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au035"><ce:given-name>Mikel</ce:given-name><ce:surname>Luján</ce:surname><ce:cross-ref id="ar040" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au040"><ce:given-name>José</ce:given-name><ce:surname>Miguel-Alonso</ce:surname><ce:cross-ref id="ar045" refid="af020"><ce:sup loc="post">d</ce:sup></ce:cross-ref></ce:author><ce:author id="au045"><ce:given-name>Eustace</ce:given-name><ce:surname>Painkras</ce:surname><ce:cross-ref id="ar050" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au050"><ce:given-name>Cameron</ce:given-name><ce:surname>Patterson</ce:surname><ce:cross-ref id="ar055" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au055"><ce:given-name>Luis A.</ce:given-name><ce:surname>Plana</ce:surname><ce:cross-ref id="ar060" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au060"><ce:given-name>Alexander</ce:given-name><ce:surname>Rast</ce:surname><ce:cross-ref id="ar065" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au065"><ce:given-name>Dominic</ce:given-name><ce:surname>Richards</ce:surname><ce:cross-ref id="ar070" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au070"><ce:given-name>Yebin</ce:given-name><ce:surname>Shi</ce:surname><ce:cross-ref id="ar075" refid="af010"><ce:sup loc="post">b</ce:sup></ce:cross-ref></ce:author><ce:author id="au075"><ce:given-name>Steve</ce:given-name><ce:surname>Temple</ce:surname><ce:cross-ref id="ar080" refid="af005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au080"><ce:given-name>Jian</ce:given-name><ce:surname>Wu</ce:surname><ce:cross-ref id="ar085" refid="af025"><ce:sup loc="post">e</ce:sup></ce:cross-ref></ce:author><ce:author id="au085"><ce:given-name>Shufan</ce:given-name><ce:surname>Yang</ce:surname><ce:cross-ref id="ar090" refid="af030"><ce:sup loc="post">f</ce:sup></ce:cross-ref></ce:author><ce:affiliation id="af005"><ce:label>a</ce:label><ce:textfn>University of Manchester, Manchester, United Kingdom</ce:textfn></ce:affiliation><ce:affiliation id="af010"><ce:label>b</ce:label><ce:textfn>ARM Ltd., Cambridge, United Kingdom</ce:textfn></ce:affiliation><ce:affiliation id="af015"><ce:label>c</ce:label><ce:textfn>National University of Sciences and Technology, Islamabad, Pakistan</ce:textfn></ce:affiliation><ce:affiliation id="af020"><ce:label>d</ce:label><ce:textfn>University of the Basque Country, San Sebastian, Spain</ce:textfn></ce:affiliation><ce:affiliation id="af025"><ce:label>e</ce:label><ce:textfn>University of Utah, Salt Lake City, UT, USA</ce:textfn></ce:affiliation><ce:affiliation id="af030"><ce:label>f</ce:label><ce:textfn>University of Ulster, Belfast, United Kingdom</ce:textfn></ce:affiliation><ce:correspondence id="cor1"><ce:label>⁎</ce:label><ce:text>Corresponding author. Tel.: +44 (0) 161 275 6143; fax: +44 (0) 161 275 6204.</ce:text></ce:correspondence></ce:author-group><ce:date-received day="19" month="12" year="2011"/><ce:date-revised day="2" month="5" year="2013"/><ce:date-accepted day="4" month="9" year="2013"/><ce:abstract class="author-highlights" xml:lang="en" id="ab005" view="all"><ce:section-title id="st135">Highlights</ce:section-title><ce:abstract-sec id="as005" view="all"><ce:simple-para id="sp005" view="all"><ce:list id="l0005"><ce:list-item id="u0005"><ce:label>•</ce:label><ce:para id="p0445" view="all">Discussion of chip-level fault tolerance of SpiNNaker's design.</ce:para></ce:list-item><ce:list-item id="u0010"><ce:label>•</ce:label><ce:para id="p0450" view="all">The implemented software improves fault tolerance by providing diagnostics and reconfiguration.</ce:para></ce:list-item><ce:list-item id="u0015"><ce:label>•</ce:label><ce:para id="p0455" view="all">Exploration of communication-level fault tolerance and its effects on system scalability.</ce:para></ce:list-item><ce:list-item id="u0020"><ce:label>•</ce:label><ce:para id="p0460" view="all">Wide range of experiments showing that SpiNNaker is highly resilient to failures.</ce:para></ce:list-item></ce:list></ce:simple-para></ce:abstract-sec></ce:abstract><ce:abstract class="author" xml:lang="en" id="ab010" view="all"><ce:section-title id="st140">Abstract</ce:section-title><ce:abstract-sec id="as010" view="all"><ce:simple-para id="sp010" view="all">SpiNNaker is a biologically-inspired massively-parallel computer designed to model up to a billion spiking neurons in real-time. A full-fledged implementation of a SpiNNaker system will comprise more than 10<ce:sup loc="post">5</ce:sup> integrated circuits (half of which are SDRAMs and half multi-core systems-on-chip). Given this scale, it is unavoidable that some components fail and, in consequence, fault-tolerance is a foundation of the system design. Although the target application can tolerate a certain, low level of failures, important efforts have been devoted to incorporate different techniques for fault tolerance. This paper is devoted to discussing how hardware and software mechanisms collaborate to make SpiNNaker operate properly even in the very likely scenario of component failures and how it can tolerate system-degradation levels well above those expected.</ce:simple-para></ce:abstract-sec></ce:abstract><ce:keywords id="kg005" class="keyword" view="all"><ce:section-title id="st150">MSC</ce:section-title><ce:keyword id="k0005"><ce:text>68M15</ce:text></ce:keyword><ce:keyword id="k0010"><ce:text>94C12</ce:text></ce:keyword><ce:keyword id="k0015"><ce:text>68M10</ce:text></ce:keyword><ce:keyword id="k0020"><ce:text>68R10</ce:text></ce:keyword></ce:keywords><ce:keywords id="kg010" class="keyword" view="all"><ce:section-title id="st155">Keywords</ce:section-title><ce:keyword id="k0025"><ce:text>Fault tolerance</ce:text></ce:keyword><ce:keyword id="k0030"><ce:text>Globally asynchronous locally synchronous</ce:text></ce:keyword><ce:keyword id="k0035"><ce:text>Low power system</ce:text></ce:keyword><ce:keyword id="k0040"><ce:text>Massively-parallel architecture</ce:text></ce:keyword><ce:keyword id="k0045"><ce:text>Spiking neural networks</ce:text></ce:keyword><ce:keyword id="k0050"><ce:text>System-on-chip</ce:text></ce:keyword></ce:keywords></head><body view="all"><ce:sections><ce:section id="s0005" view="all"><ce:label>1</ce:label><ce:section-title id="st005">Introduction</ce:section-title><ce:para id="p0005" view="all">SpiNNaker is an application specific design intended to model large biological neural networks - the name "SpiNNaker" being derived from 'Spiking Neural Network architecture'. It consists of a toroidal arrangement of processing nodes, each incorporating a purpose-built, multi-core System-on-Chip (SoC) and an SDRAM memory (<ce:cross-ref id="c0200" refid="f0005">Fig. 1</ce:cross-ref><ce:float-anchor refid="f0005"/>). Neurons are modelled in software running on embedded ARM968 processors; each core is intended to model a nominal 1000 neurons. Small-scale SpiNNaker systems have successfully been used as control systems in embedded applications <ce:cross-ref id="c0005" refid="b0005">[1]</ce:cross-ref>, providing robots with real-time <ce:italic>stimulus-response</ce:italic> behaviour as described in <ce:cross-ref id="c0010" refid="b0010">[2]</ce:cross-ref>. However the ultimate aiming of the project is to construct a machine able to simulate up to <mml:math altimg="si5.gif" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> neurons in real time. To put this number in context some small primates have brains with slightly lower neuron counts whereas the human brain has roughly 86 times this number <ce:cross-ref id="c0015" refid="b0015">[3]</ce:cross-ref>. To reach this number of neurons more than one hundred thousand integrated circuits will be needed (half of which are SpiNNaker chips and the other half SDRAMs).</ce:para><ce:para id="p0010" view="all">A system of this scale may be expected to suffer component failures and many features of its design are included to provide a certain degree of fault tolerance. These features can sometimes be justified on cost alone: the overall yield for the 100<ce:hsp sp="0.25"/>mm<ce:sup loc="post">2</ce:sup> SpiNNaker SoC was estimated, using public domain yield statistics on a 20-core, at 50% fault-free chips, 25% single-fault chips, 10% two-fault chips and the remaining 15% will be unusable due to critical failures. Early test on the production chip (in <ce:cross-ref id="c0205" refid="f0010">Fig. 2</ce:cross-ref><ce:float-anchor refid="f0010"/>) show similar, if rather better, yield characteristics (see Section <ce:cross-ref id="c0210" refid="s0030">4</ce:cross-ref>). The 35% of chips having one or two faults would not be usable without fault tolerance features. Fault tolerance is addressed at a number of levels, not least the application itself, which is intrinsically fault-tolerant. SpiNNaker incorporates measures to enable continued function in the presence of faults; in fact it has been designed as a power- and cost-effective fault-tolerant platform.</ce:para><ce:para id="p0015" view="all">The major defence against faults in such a system is the massive processing resource. Processors are almost free and dedicating a small proportion of the processing power for system management and reconfiguration yields significant distributed 'intelligence' without much impact on the application. From the outset the intention has been to allocate one core on each SoC entirely to system management; if this eventually proves insufficient it is simple to delegate a second core to this task. Cores devoted to system management can identify and map around failed devices at run time.</ce:para><ce:para id="p0020" view="all">Particular attention has been paid to inter-chip communications where link failures or transient congestion may be routed around rapidly without software intervention. Finally some more conventional techniques - such as automatic CRC generation and checking and watchdog timers - are employed in each processing node. As a large-scale system has not yet been built the full possibilities of software reconfiguration have yet to be explored. However statistical models of the architecture have been developed and used to verify the principles, and the hardware mechanisms themselves have been tested in silicon in small-scale (4 chip) systems. The construction of a larger machine is in progress.</ce:para></ce:section><ce:section id="s0010" view="all"><ce:label>2</ce:label><ce:section-title id="st010">Background</ce:section-title><ce:para id="p0025" view="all">This section reviews common terminology on fault-tolerance and microelectronics, introducing several important concepts related to SpiNNaker and putting in context how fault tolerance is addressed.</ce:para><ce:para id="p0030" view="all">Throughout this paper, we differentiate between soft and hard errors. <ce:italic>Soft errors</ce:italic> are transient errors - usually produced by electromagnetic noise - that affect the state of a bit to an extent that it swaps its value (from 0 to 1, or vice versa). Cosmic rays are nowadays the main cause of soft errors <ce:cross-ref id="c0020" refid="b0020">[4]</ce:cross-ref>. In contrast, <ce:italic>hard errors</ce:italic> are permanent errors due to physical defects, usually introduced during fabrication. Some authors consider a third type of error, <ce:italic>intermittent</ce:italic> failures in which a component is barely stable and behaves irregularly as correct or as erroneous, the main triggers for one behaviour or the other being environmental factors (such as temperature, or voltage) <ce:cross-ref id="c0025" refid="b0025">[5]</ce:cross-ref>. We consider intermittent failures as hard failures and deactivate components that exhibit this behaviour.</ce:para><ce:para id="p0035" view="all">All units within a SpiNNaker chip are provided with two levels of reset. A 'soft' reset is a signal to the state machines to abandon their operation <ce:italic>at the next convenient opportunity</ce:italic>, thus allowing any handshakes to complete first. The 'hard' reset involves <ce:italic>switching off</ce:italic> a component and restarting it in order to reach its initial state. Note that the latter is really intended only for power-up.</ce:para><ce:para id="p0040" view="all"><ce:italic>Globally Asynchronous Locally Synchronous</ce:italic> (GALS) technology offers the possibility of synchronous and asynchronous logic to coexist, obtaining the best of each world <ce:cross-ref id="c0030" refid="b0030">[6]</ce:cross-ref>. Most devices use synchronous logic whereas communication between them is implemented using asynchronous fabrics. GALS simplifies development and reduces power consumption but, in contrast, makes fault tolerance difficult due to the lack of time awareness.</ce:para><ce:para id="p0045" view="all">The three main elements for fault-tolerance are the Host, the System Controller and the Monitor Processor and Process. The <ce:italic>Host</ce:italic> is a regular computer which runs an application that interfaces with SpiNNaker giving the Host a range of control operations over the hardware. The Host is in charge of starting the system, uploading neural applications and data and looking after the status of the system once it starts its execution. It includes a User Interface that allows exploration of the status of SpiNNaker components (see <ce:cross-ref id="c0215" refid="f0015">Fig. 3</ce:cross-ref><ce:float-anchor refid="f0015"/>). The <ce:italic>Monitor Process</ce:italic> is the application in charge of controlling the status of each chip components. It requires a dedicated core, namely the <ce:italic>Monitor Processor</ce:italic>, which is selected during the boot-up process from all the functional cores. The Monitor Process uses the <ce:italic>System Controller</ce:italic>, a specialized piece of hardware, to detect and try to heal failing components. The System Controller supports soft and hard resets of the different components within a chip and also communicates with the System Controller in neighbouring chips.</ce:para><ce:para id="p0050" view="all">Watchdog devices are added to the design in order to supervise the correct operation of critical components such as the Monitor Process, or the communication ports. If a component does not respond for a predetermined amount of time, the watchdog will apply 'soft' reset first, only resorting to 'hard' reset if this fails. If both resets fail the watchdog will mark the component as faulty in the System Controller so that the Monitor Process can switch it off or, alternatively, try more elaborated nursing.</ce:para><ce:para id="p0055" view="all">SpiNNaker's fault tolerance relies mainly on redundancy: 18 cores, 6 output links, 2 PLLs (phase locked loops) and the memory subsystem. The main strength of this redundancy is that components do not have their identifiers hard-coded, and therefore the functionality of one component can be covered seamlessly by any redundant one. Practically, this means that critical components such as the Monitor Processor are extremely reliable.</ce:para><ce:para id="p0060" view="all"><ce:cross-ref id="c0220" refid="t0005">Table 1</ce:cross-ref><ce:float-anchor refid="t0005"/> shows the relative areas of the different components of the chip to put in context their likelihood of fail. The largest part of the chip is devoted to cores and TCMs, the most redundant and therefore less critical components of SpiNNaker.</ce:para></ce:section><ce:section id="s0015" view="all"><ce:label>3</ce:label><ce:section-title id="st015">Overview of SpiNNaker</ce:section-title><ce:section id="s0020" view="all"><ce:label>3.1</ce:label><ce:section-title id="st020">Application-induced architecture</ce:section-title><ce:para id="p0065" view="all">SpiNNaker simulates spiking neural networks using Izhikevich <ce:cross-ref id="c0035" refid="b0035">[7]</ce:cross-ref> and Leaky Integrate and Fire <ce:cross-ref id="c0040" refid="b0040">[8]</ce:cross-ref> models which emulate the dynamics of biological neural systems. However SpiNNaker has an architecture general enough to run other flavours of application <ce:cross-ref id="c0045" refid="b0045">[9]</ce:cross-ref>. For example it also supports Multilayer Perceptron models <ce:cross-ref id="c0050" refid="b0050">[10]</ce:cross-ref> and other non-neural applications such as ray-tracing, many body interaction, finite element analysis and analogue circuit simulation.</ce:para><ce:para id="p0070" view="all">Spiking neural systems have abundant parallelism and no explicit requirement of coherence as only local information is used by the neurons. The process is as follows: each neuron has a membrane potential which is affected by incoming stimuli (signals). If the membrane potential exceeds a given threshold, the neuron discharges and fires a signal (a so-called <ce:italic>spike</ce:italic>) which is transmitted to all neurons connected through a synaptic connection, typically in the order of <mml:math altimg="si6.gif" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> <ce:cross-ref id="c0055" refid="b0055">[11]</ce:cross-ref>. Biological neurons work in a noisy environment <ce:cross-ref id="c0060" refid="b0060">[12]</ce:cross-ref> and, indeed, die during normal operation (adult humans lose about one neuron per second <ce:cross-ref id="c0065" refid="b0065">[13]</ce:cross-ref>). Thus their operation is neither perfect nor deterministic.</ce:para><ce:para id="p0075" view="all">The SpiNNaker architecture reflects this behaviour. Neurons are modelled as event-driven applications executed by the processing cores. Spikes are represented by short network packets (40 bits) using Address-Event Representation (AER), a format widely used in neural network models <ce:cross-refs id="r0005" refid="b0070 b0075 b0080">[14-16]</ce:cross-refs>. Packets are <ce:italic>multicast</ce:italic> routed in hardware with the on-chip routers replicating them as necessary to reach all their destinations.</ce:para><ce:para id="p0080" view="all">Given that digital electronics are orders of magnitude faster than the biological process - for example, biological spikes are propagated through an axon for up to 20<ce:hsp sp="0.25"/>ms while transmitting a packet through the SpiNNaker interconnection network should take a few <ce:italic>microseconds</ce:italic> at most - it is possible to multiplex many neurons onto a processor and many spikes onto a network although the consequence of a single-point failure can easily be more serious than the loss of one neuron.</ce:para></ce:section><ce:section id="s0025" view="all"><ce:label>3.2</ce:label><ce:section-title id="st025">SpiNNaker chip</ce:section-title><ce:para id="p0085" view="all">The basic unit of the system is the SpiNNaker chip (<ce:cross-ref id="c0225" refid="f0020">Fig. 4)</ce:cross-ref><ce:float-anchor refid="f0020"/>, custom GALS SoC with a network router and 18 cores sharing some resources such as a SRAM, a boot ROM, a System Controller, an Ethernet interface and an 128Mbyte off-chip (but in-package, see <ce:cross-ref id="c0230" refid="f0010">Fig. 2</ce:cross-ref>) SDRAM.</ce:para><ce:para id="p0090" view="all">Each <ce:italic>processing core</ce:italic> is an ARM968, with two <ce:italic>private</ce:italic> tightly coupled memories for instructions (ITCM) and data (DTCM), some peripherals - including direct access to the Comms NoC - and a bridge to the shared resources.</ce:para></ce:section></ce:section><ce:section id="s0030" view="all"><ce:label>4</ce:label><ce:section-title id="st030">Fault tolerant architecture</ce:section-title><ce:para id="p0095" view="all">From Section <ce:cross-ref id="c0235" refid="s0015">3</ce:cross-ref> some fault-tolerant features will already be apparent. Firstly the application itself is robust against minor perturbations in timing and should tolerate a percentage of missing spikes and neurons. Secondly, there is a huge hardware resource available which provides a high degree of redundancy.</ce:para><ce:para id="p0100" view="all">Although each node has 18 cores, the intended use does not <ce:italic>require</ce:italic> any specific number of cores, merely (any) one to provide node control and <ce:italic>some</ce:italic> others to run the application. Indeed for cost purposes it is intended to use some flawed devices; yield estimates suggest that this may improve the usability of manufactured dice from 50% to around 80%. Based on the area use of the die the majority of flaws may be expected to be in local memories; these may leave a core degraded but still usable although the simplest action is still to shut it down.</ce:para><ce:para id="p0105" view="all">Preliminary evidence from the first batch of fabricated chips suggests these estimates to be appropriate if slightly pessimistic. Of 46 chips, 30 (65%) were flawless chips, 12 (26%) have 17 working cores and 4 (9%) have more serious problems. Of the 12, 11 have private memory faults and one a peripheral logic fault. From this small sample it seems likely that 42 of 46 (93%) dice will be serviceable because manufacturing faults can be tolerated. This represents an increase of roughly 40% in terms of achievable computing power (from 540 to 744 cores).</ce:para><ce:para id="p0110" view="all">This redundancy can also be used to protect against (less likely) run-time faults by offloading work. By keeping a stand-by core on each node a run-time fault can be accommodated without too much effort, particularly as the majority of the data is held in the separate, shared SDRAM. The SDRAM devices are 'known good' before packaging. Each provides a node with more than its anticipated store requirement, thus there is capacity to test and map around any dubious region. This is one of the tasks for the local Monitor Processor.</ce:para><ce:para id="p0115" view="all">In addition to redundancy, a number of features have been included either as design considerations or specifically for fault-tolerance. <ce:cross-ref id="c0240" refid="f0025">Fig. 5</ce:cross-ref><ce:float-anchor refid="f0025"/> shows a map of the expected failure types and the mechanisms provided to reduce their impact in the usability of SpiNNaker.</ce:para></ce:section><ce:section id="s0035" view="all"><ce:label>5</ce:label><ce:section-title id="st035">Diagnostics and dynamic configuration</ce:section-title><ce:para id="p0120" view="all">System routines can clearly be split into two: (i) power-on testing and initial configuration, and (ii) isolation and reconfiguration during normal operation. In either case, the interaction between hardware and system software in each chip is coordinated by the Monitor Processor which maintains a continuously updated state (good, fault, disabled, <ce:italic>etc</ce:italic>.) of the chip components. The System Controller can disable or reconfigure chip components. In extreme failure cases the System Controller can be accessed from a neighbouring SpiNNaker chip using a local debug facility.</ce:para><ce:section id="s0040" view="all"><ce:label>5.1</ce:label><ce:section-title id="st040">Power-on diagnostics and configuration</ce:section-title><ce:para id="p0125" view="all">Each SpiNNaker chip performs diagnostics and initialization using minimal system software stored in the Boot ROM. In this stage each processing core performs a power-on self-test and initialisation of its private peripherals. Healthy cores then compete to access the System Controller monitor election register, the winner becoming the Monitor Processor. The remaining cores simply register their state in the System Controller and stall until the Monitor completes the node configuration (including detailed chip-level tests, initialising shared resources and detecting any connected Ethernet port). All chip-level results are stored in the System Controller.</ce:para><ce:para id="p0130" view="all">After this step, nodes enter a listening mode awaiting external instructions. The host machine designates one or more Ethernet attached nodes to receive the system image to be executed by the Monitor Processors. The image is transmitted in blocks to the Ethernet attached Monitors which compile the image, perform a CRC check and copy it to their local memory where it can be executed. The system image informs the host machine and propagates itself to its neighbours; these neighbours send it forward their neighbours, and so on. This way the system image is flood-filled in a redundant manner as each chip will receive several copies of the system image (see below). Once system boot is complete, the Monitor Processors test connections to neighbouring chips to record any faulty link or neighbour.</ce:para><ce:para id="p0135" view="all">The host nominates one Ethernet-attached chip as the <ce:italic>Reference Chip</ce:italic>, making it the origin address, <mml:math altimg="si7.gif" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mtext>,</mml:mtext><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, of the network, notifying it of the topological characteristics, such as the number of chips. The Reference Chip then broadcasts its address to its six neighbours, and so on. This generates a second wave through the network that enables each chip to compute its relative address in the network topology and configure point-to-point routing tables.</ce:para><ce:section id="s0045" view="all"><ce:label>5.1.1</ce:label><ce:section-title id="st045">Evaluation of flood filling policies</ce:section-title><ce:para id="p0140" view="all">Data loading can be done via several <ce:italic>flood-fill</ce:italic> strategies, each offering different performance and fault resilience compromises. Several of these strategies were evaluated previously <ce:cross-ref id="c0070" refid="b0085">[17]</ce:cross-ref>, but when that evaluation was performed, <ce:italic>broadcast</ce:italic> packets were addressed to all neighbours and consequently most strategies had to use point-to-point (<ce:italic>unicast</ce:italic>) packets, with the consequent overloading of the injection ports. To overcome this overhead a selective multicast able to forward packets to a subset of the neighbours was included in the final design.</ce:para><ce:para id="p0145" view="all">The following evaluation considers several strategies using this selective multicast. <ce:cross-ref id="c0245" refid="f0030">Fig. 6</ce:cross-ref><ce:float-anchor refid="f0030"/> summarizes the results of an event-driven simulation of the application loading process in the largest system configuration (256 ×256 nodes). The top two graphs consider SpiNNaker systems without failures and are intended to show the performance (time consumed in the floodfill). The bottom two consider systems with different link failure configurations and show the resilience level provided by each strategy. Next we explain how these graphs can be interpreted.</ce:para><ce:para id="p0150" view="all">Seven different flood-fill policies were considered in the simulations:<ce:list id="l0010"><ce:list-item id="u0025"><ce:label>•</ce:label><ce:para id="p0465" view="all"><ce:italic>bcast</ce:italic> sends the packet to all neighbouring chips.</ce:para></ce:list-item><ce:list-item id="u0030"><ce:label>•</ce:label><ce:para id="p0470" view="all"><ce:italic>2msg</ce:italic> sends the packet only to the neighbours in the positive <ce:italic>X</ce:italic> and <ce:italic>Y</ce:italic> directions. This is the minimum number of neighbours required to perform an efficient flooding.</ce:para></ce:list-item><ce:list-item id="u0035"><ce:label>•</ce:label><ce:para id="p0475" view="all"><ce:italic>3msg</ce:italic> sends the packet to the neighbours in positive <ce:italic>X</ce:italic>, <ce:italic>Y</ce:italic> and <ce:italic>XY</ce:italic> diagonal.</ce:para></ce:list-item><ce:list-item id="u0040"><ce:label>•</ce:label><ce:para id="p0480" view="all"><ce:italic>5msg</ce:italic> sends the packet to all the neighbours but the one the original packet was received from.</ce:para></ce:list-item><ce:list-item id="u0045"><ce:label>•</ce:label><ce:para id="p0485" view="all"><ce:italic>randP</ce:italic> sends the packet in the positive <ce:italic>X</ce:italic> and <ce:italic>Y</ce:italic> directions and in addition randomly to each of the other directions with a P% probability. We considered 25% (<ce:italic>rand25</ce:italic>), 50% (<ce:italic>rand50</ce:italic>) and 75% (<ce:italic>rand75</ce:italic>) in our evaluation.</ce:para></ce:list-item></ce:list>In the simulations considering several Ethernet ports, nodes located at (0, 0), (128, 128), (128, 0) and (0, 128) are connected to the host.</ce:para><ce:para id="p0155" view="all">The results without failures in <ce:cross-ref id="c0250" refid="f0030">Fig. 6</ce:cross-ref>(a) and (b) show that (i) different flooding strategies provide diverse performance levels, (ii) given the 2D-pipelined nature of the application loading procedure, the loading times are not affected substantially by the network size; and (iii) similarly, the number of Ethernet-connected nodes does not affect significantly the time required to load the application.</ce:para><ce:para id="p0160" view="all">The configurations with failures - see <ce:cross-ref id="c0255" refid="f0030">Fig. 6</ce:cross-ref>(c) and (d) - present the normalized number of undelivered packets. Points that are not shown in the plot mean that the loading process was successful. The failure distributions considered in this study are the following.<ce:list id="l0015"><ce:list-item id="u0050"><ce:label>•</ce:label><ce:para id="p0490" view="all"><ce:italic>vert</ce:italic> represents a configuration where all the links along the <ce:italic>Y</ce:italic>-axis in the bisection are treated as faulty, leading to a network split in vertical columns.</ce:para></ce:list-item><ce:list-item id="u0055"><ce:label>•</ce:label><ce:para id="p0495" view="all"><ce:italic>horiz</ce:italic> represents a similar configuration, but affecting the horizontal axis.</ce:para></ce:list-item><ce:list-item id="u0060"><ce:label>•</ce:label><ce:para id="p0500" view="all"><ce:italic>cross</ce:italic> represents the union of <ce:italic>horiz</ce:italic> and <ce:italic>vert</ce:italic>. Small-scale examples of these three configurations are shown in <ce:cross-ref id="c0260" refid="f0035">Fig. 7</ce:cross-ref><ce:float-anchor refid="f0035"/>.</ce:para></ce:list-item><ce:list-item id="u0065"><ce:label>•</ce:label><ce:para id="p0505" view="all">The remaining configurations represent uniform random sets of link failures: 1536 (<ce:italic>rnd1</ce:italic>), 3072 (<ce:italic>rnd2</ce:italic>), 6144 (<ce:italic>rnd3</ce:italic>), 12,288 (<ce:italic>rnd4</ce:italic>) and 24,576 (<ce:italic>rnd5</ce:italic>).</ce:para></ce:list-item></ce:list>In general, those strategies sending more packets are less likely to lose packets but at the price of increasing the time required to finalize the whole process. In all cases, it will take only from 5 to 15 ms to load an application completely. Results also show that increasing the number of Ethernet connections improves robustness, especially in scenarios with multiple failures.</ce:para><ce:para id="p0165" view="all">We conclude that the SpiNNaker configuration process is efficient, scalable and robust. Moreover, there is a reasonable range of distribution strategies that allow trade-offs between speed and fault-resilience.</ce:para></ce:section></ce:section><ce:section id="s0050" view="all"><ce:label>5.2</ce:label><ce:section-title id="st050">Run-time reconfiguration</ce:section-title><ce:para id="p0170" view="all">During regular operation, the Monitor Processor periodically checks and updates the state of chip resources, including the state of the links to its neighbours, in the System Controller. Any Monitor Processor can activate the <ce:italic>neighbour diagnostic and recovery</ce:italic> routine if it suspects a neighbour chip is not working properly. This <ce:italic>nurse</ce:italic> Chip will 'peek and poke' the remote System Controller to identify any healthy cores. It will first try to change the remote Monitor Processor, then try to overcome a Boot ROM failure by copying the boot-up code to the remote System RAM and remapping the remote Boot ROM and System RAM. Finally, the Nurse Chip will reset the remote chip to attempt to recover from a transient fault. If nothing works, the failed chip is isolated by disabling its clocks.</ce:para><ce:para id="p0175" view="all">When cores or chips are detected to be faulty, the system tries to migrate their functionality (typically neurons) to other cores. This process is in principle straightforward, however depending on the failure some of the neural information may be impossible to recover. For example, to migrate from a chip because it cannot access its SDRAM, only the neural information stored in local memory can be recovered. The way to regenerate <ce:italic>unrecoverable</ce:italic> information will depend on the executed application but, as discussed before, losing neurons is acceptable in a biological brain and therefore it may be so in the simulated application.</ce:para><ce:para id="p0180" view="all">When routers or links stop working properly, part of the routing tables may need to be reconstructed dynamically to avoid unreliable areas of the network. When a route is destroyed, the system can generate new routes by the back propagation of a routing key from the destination node to the source node. The host system will collect the required information from this procedure and will generate and propagate the updated routing tables. Alternatively, a distributed reconfiguration may rely on the Monitor Processes around the failing components for the generation and propagation of the updated routing tables.</ce:para><ce:para id="p0185" view="all">Finally, each SpiNNaker chip is provided with a watchdog timer which detects when the Monitor Processor has not responded for a long time. When this is detected, the recovery process first tries to recover the Monitor Processor by soft resetting it. If this measure does not solve the problem, then it hard resets the chip, forcing the System Controller to select another core as a Monitor Processor.</ce:para></ce:section></ce:section><ce:section id="s0055" view="all"><ce:label>6</ce:label><ce:section-title id="st055">Communications fault tolerance</ce:section-title><ce:para id="p0190" view="all">Given that the supported application is communication-intensive the interconnection fabric of SpiNNaker is another critical component and therefore great effort has been devoted to design a robust and stable infrastructure.</ce:para><ce:section id="s0060" view="all"><ce:label>6.1</ce:label><ce:section-title id="st060">On-chip and off-chip communication</ce:section-title><ce:para id="p0195" view="all">The <ce:italic>Comms NoC</ce:italic> connects the processing cores via a custom on-chip router offering a bandwidth of up to 1<ce:hsp sp="0.25"/>GByte/s. The <ce:italic>Communications Controller</ce:italic> within each processing core handles packets on behalf of its simulated neurons and interfaces with the Comms NoC. Together the on-chip router and the self-timed fabric seamlessly extend on-chip communications onto inter-chip connections.</ce:para><ce:para id="p0200" view="all">The Comms NoC has 18 ports for internal use of the processing cores and six ports to communicate with six adjacent chips (<ce:cross-ref id="c0265" refid="f0020">Fig. 4</ce:cross-ref>). External ports contain two independent, unidirectional self-timed chip-to-chip interfaces, one for transmitting and the other one for receiving data; i.e. a failure in a link or interface only affects one of the directions. Asynchronously arriving packets to the router are arbitrated and serialised. The router can process one packet per clock cycle. It is expected that the <ce:italic>average</ce:italic> traffic demand will be much lower than this. In the event of a 'collision' packets can be delayed arbitrarily and buffering between routers helps to accommodate this. Packets are checked for integrity on arrival at the router; faulty packets are dropped into a register where they can be examined by the local Monitor Processor. Faults may be caused by corruption in transit - indicated by parity and framing errors - or by being outdated.</ce:para><ce:para id="p0205" view="all">AER packet routing is done with a 1024 entry associative look-up table. Each table entry has its own bitmap mask that will be applied to the source address before it is compared with the table entries in order. If an address is not found then the packet is <ce:italic>default</ce:italic> routed to the port opposite the one it came from. Table entries are therefore only used when packets turn or bifurcate. Each table entry can be deactivated independently if not functioning properly; there is therefore some flexibility (potential redundancy) in the way table entries are used. As the table uses standard cell latches the soft error rate is expected to be very low.</ce:para><ce:para id="p0210" view="all">Packets may be replicated to any subset of the router's outputs. They are sent when <ce:italic>all</ce:italic> the desired outputs are ready to accept them, stalling until this time. In the event of an output being blocked this could cause problems and backlog the router. Thus, after a programmable interval, the router attempts to route around any blocked (or broken) external links through a so-called <ce:italic>emergency route</ce:italic>. If this still fails after another programmable interval the offending packet is dropped into a local register and the subsequent packet is tried instead. The Monitor Processor may be interrupted to examine the dropped packet and resend it - perhaps suitably modified - later.</ce:para><ce:para id="p0215" view="all">Emergency routed packets take advantage of the triangular topology to try to reach their destinations, as shown in <ce:cross-ref id="c0270" refid="f0040">Fig. 8</ce:cross-ref><ce:float-anchor refid="f0040"/>. Emergency routes are always adjacent to the intended path and the subsequent turns are therefore predefined. This is coded into the short packet header.</ce:para><ce:para id="p0220" view="all">A particular concern is the possible occurrence of (network-level) deadlock. Conventional HPC networks avoid the formation of such chains by means of complex combinations of topology, routing algorithms and flow-control techniques <ce:cross-ref id="c0075" refid="b0090">[18]</ce:cross-ref>. Given that routing is application specific a different approach to deadlock avoidance was required. As neural applications do not require delivery guarantees, a time-out based, packet-dropping mechanism suffices, provided that the proportion of lost packets is low.</ce:para></ce:section><ce:section id="s0065" view="all"><ce:label>6.2</ce:label><ce:section-title id="st065">Topological robustness</ce:section-title><ce:para id="p0225" view="all">To assess the robustness of the two-dimensional triangular torus topology we tested how it loses connectivity in the presence of link failures. A typical manufacturing process can be expected to produce components with a functional life of well over 10 years. With a very pessimistic scenario model of a 5-year mean time to failure (MTTF) with sigma of 2 years, the expected number of link failures in a complete SpiNNaker system (65,536 nodes) for any given day (<mml:math altimg="si8.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mtext>day</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math>) would lie between 160 and 360.</ce:para><ce:para id="p0230" view="all">We contrasted SpiNNaker topology with regular two- and three-dimensional tori for 65,536 nodes. The 2-D topologies are arranged as square networks of <mml:math altimg="si9.gif" overflow="scroll"><mml:mrow><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:math> nodes whereas the 3-D torus is arranged as a <mml:math altimg="si10.gif" overflow="scroll"><mml:mrow><mml:mn>64</mml:mn><mml:mo>×</mml:mo><mml:mn>32</mml:mn><mml:mo>×</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:math> network.</ce:para><ce:para id="p0235" view="all">We assessed how the three topologies lose node-connectivity as the number of link failures increases from 1 to 65,536. A depth-first search algorithm was used to calculate this figure for <mml:math altimg="si11.gif" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> random uniform failure configurations. The average of these <mml:math altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> runs is plotted in <ce:cross-ref id="c0275" refid="f0045">Fig. 9</ce:cross-ref><ce:float-anchor refid="f0045"/>. In the figure we can see that the triangular two-dimensional torus implemented in SpiNNaker provides a robustness level similar to a three-dimensional torus. Both topologies can support up to 8,192 random link failures without any of the nodes losing connectivity with the rest of the system, more than one order of magnitude above (<mml:math altimg="si13.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mtext>day</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math>). On average tens of thousands of link failures are required to lose one or more nodes. This robustness motivates the use of the triangular torus topology in SpiNNaker.</ce:para></ce:section><ce:section id="s0070" view="all"><ce:label>6.3</ce:label><ce:section-title id="st070">Interconnect stability under severe degradation</ce:section-title><ce:para id="p0240" view="all">The packet dropping mechanism provides a deadlock-free interconnection network. However, there is a loss of information that has to be assessed. Spiking neuron systems can work when a few messages are lost but, even in very pessimistic scenarios, the number of dropped packets should be low (below 1 packet per million. Approximatelly 1 packet each 1,500 cycles in the following experiments). Simulation has verified that the network can deal with loads well-above the expected without significantly impacting applications (packet delay is acceptable) <ce:cross-ref id="c0080" refid="b0105">[21]</ce:cross-ref>.</ce:para><ce:para id="p0245" view="all">The simulations model a <mml:math altimg="si14.gif" overflow="scroll"><mml:mrow><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:math> network considering scenarios in which the network suffers different levels of hard failures. To account for the real-time constraint, this section investigates the temporal evolution of the system and focuses on <ce:italic>stability</ce:italic>, understood as the variability (which should be low) of the figures of merit and assesses the effectiveness of the emergency routing mechanism.</ce:para><ce:section id="s0075" view="all"><ce:label>6.3.1</ce:label><ce:section-title id="st075">Simulation model of the SpiNNaker network</ce:section-title><ce:para id="p0250" view="all">A simplified model of the SpiNNaker interconnection infrastructure has been implemented in INSEE <ce:cross-ref id="c0085" refid="b0095">[19]</ce:cross-ref>. It includes the topological description of the system and a model of the router.</ce:para><ce:para id="p0255" view="all">Time is modelled in terms of abstract network <ce:italic>cycles</ce:italic> the time to route and forward a packet (1 network cycle<ce:hsp sp="0.25"/>≈<ce:hsp sp="0.25"/>10 processor cycles). A network node represents a complete SpiNNaker chip, with all its cores and its router. Nodes are modelled as independent traffic sources that inject packets following a Bernoulli temporal distribution that can be parameterized to generate any chosen injection rate. The spatial distribution of the traffic is uniform.</ce:para><ce:para id="p0260" view="all">All ports are modelled as a single four-packet queue. If this is full and the node tries to inject a packet, it is dropped. Communications are point-to-point. Routing tables are not implemented, using Dimension Order Routing instead. This emulates the expected shape of communications - two straight lines with one inflection point <ce:cross-ref id="c0090" refid="b0100">[20]</ce:cross-ref>. As discussed in Section <ce:cross-ref id="c0280" refid="s0035">5</ce:cross-ref>, the SpiNNaker system is aware of network failures and can modify its routing tables to avoid conflictive areas. In contrast, DOR is oblivious and therefore unaware of network failures so our results should be taken as pessimistic</ce:para><ce:para id="p0265" view="all">The experiments consider systems with 0 to 1024 link failures which covers scenarios well above <mml:math altimg="si15.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mtext>day</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math> (as discussed before). Consequently this evaluation should be understood as a <ce:italic>worst-case</ce:italic> study.</ce:para></ce:section><ce:section id="s0080" view="all"><ce:label>6.3.2</ce:label><ce:section-title id="st080">Experiments and discussion of results</ce:section-title><ce:para id="p0270" view="all">In the following experimental work, we will use the maximum network load expected during regular operational levels of SpiNNaker which was derived in previous research <ce:cross-ref id="c0095" refid="b0105">[21]</ce:cross-ref>. We show the evolution of a SpiNNaker network degrading progressively from 0 to 1024 random link failures which are introduced at the beginning of every sampling period (5,000 cycles). The figures of interest are accepted load, number of dropped packets and packet latency figures (average and maximum). Router parameters are fixed to the values suggested by previous experiments <ce:cross-ref id="c0100" refid="b0105">[21]</ce:cross-ref>. To assess the impact of emergency routing on system stability, we plot results <ce:italic>without</ce:italic> (<ce:cross-ref id="c0285" refid="f0050">Fig. 10</ce:cross-ref><ce:float-anchor refid="f0050"/>a) and <ce:italic>with</ce:italic> this mechanism (<ce:cross-ref id="c0290" refid="f0050">Fig. 10</ce:cross-ref>b).</ce:para><ce:para id="p0275" view="all">To better understand the graphs, notice that the <ce:italic>X</ce:italic>-axis measures time (cycles). The labels at the top (1, 2, 4,<ce:hsp sp="0.12"/>…<ce:hsp sp="0.12"/>,<ce:hsp sp="0.12"/>1024) indicate the total number of failures at the corresponding time: during the first 5 kcycles the network is fully operative, from 5k to 10k there is a single link failure, from 10k to 15k there are two failures, and so on. Each performance metric has its own unit, indicated in the <ce:italic>Y</ce:italic>-axes: packets (for the dropped packets line), cycles (for the average and maximum delay lines) and packets/cycle/node (for the accepted load line). Note that plotted data, including the number of dropped packets, are not cumulative, but correspond to 10-cycle measurement periods.</ce:para><ce:para id="p0280" view="all"><ce:cross-ref id="c0295" refid="f0050">Fig. 10</ce:cross-ref>(a) shows how the progressive introduction of failures results in a high variability of performance metrics when emergency routing is not activated. Accepted load drops by up to 25%, maximum delay noticeably fluctuates and the number of dropped packets grows linearly with the number of link failures. For clarity, in the graphs the <ce:italic>Y</ce:italic>-axis is bounded by 0 and 500, which leaves out the number of dropped packets for 512 failures (around 800) and 1024 failures (around 1600). We can see that even with a single failure the system with emergency routing deactivated (approx. 1 packet dropped every 50 cycles) noticeably exceeds the acceptable limit.</ce:para><ce:para id="p0285" view="all">In contrast, evolution with the emergency routing activated, <ce:cross-ref id="c0300" refid="f0050">Fig. 10</ce:cross-ref>(b), shows very stable performance metrics. Only some minor peaks in the maximum delay can be observed. The most remarkable difference is in the number of dropped packets: no packets are dropped for experiments with fewer than 512 failures. Considering that these scenarios are well beyond the described pessimistic range of failures (160-360), we can confirm that the emergency routing plays a major role in improving fault tolerance at the network level. It is also worth noticing that, in all cases, when failures are introduced in the system we do not observe significant transient periods. This means that, after a failure, the system reaches a stable situation very rapidly.</ce:para><ce:para id="p0290" view="all">The conclusion is that the SpiNNaker interconnection network provides a highly stable communications fabric for the real-time simulation of spiking neurons. Even under very pessimistic scenarios the interconnection network does not show significant performance fluctuations and degrades gracefully.</ce:para></ce:section></ce:section><ce:section id="s0085" view="all"><ce:label>6.4</ce:label><ce:section-title id="st085">Chip-to-chip interfaces</ce:section-title><ce:para id="p0295" view="all">The self-timed communication fabric is implemented using handshake protocols because of their advantages for large networks:<ce:list id="l0020"><ce:list-item id="u0070"><ce:label>•</ce:label><ce:para id="p0510" view="all">Chips can be interconnected without regard to wiring delays which simplifies machine construction as some chips will be adjacent on a PCB whilst others may require considerable cabling or buffering with potential for delays and skew.</ce:para></ce:list-item><ce:list-item id="u0075"><ce:label>•</ce:label><ce:para id="p0515" view="all">Power economy by limiting logic transitions (no clock information is transmitted).</ce:para></ce:list-item><ce:list-item id="u0080"><ce:label>•</ce:label><ce:para id="p0520" view="all">Adequately high speed is retained.</ce:para></ce:list-item><ce:list-item id="u0085"><ce:label>•</ce:label><ce:para id="p0525" view="all">Well suited to short, intermittent transmissions - appropriate for neural communications.</ce:para></ce:list-item></ce:list>There is, however, a significant drawback to handshaking links: in the presence of noise they are prone to deadlock. In this subsection these are deadlocks at the <ce:italic>interface</ce:italic> level, not to be confused with the previously discussed network-level deadlocks.</ce:para><ce:para id="p0300" view="all">A <ce:italic>handshake link</ce:italic> can be thought of as passing a data token from the sender to the receiver which the handshake returns so that the next data can be sent. Noise on the link may not only corrupt the data but also this control information, removing or introducing other tokens so that the sender and receiver lose coherence. In the most serious case, a lost token can result in each waiting for the other and the data link cannot recover. Timeout is not possible as there is no concept of time, only sequencing.</ce:para><ce:para id="p0305" view="all">The on-chip network uses Silistix CHAIN <ce:cross-ref id="c0105" refid="b0115">[23]</ce:cross-ref> interconnection with 3-of-6 return-to-zero (RTZ) coding <ce:cross-ref id="c0110" refid="b0110">[22]</ce:cross-ref>. This provides a convenient symbol set with 20 codes of which 16 are used. A separate channel provides an End-of-Packet (EoP) marker. The inter-chip links use a different protocol to balance speed, pin usage and (particularly) power consumption. Each four bit token is encoded as a 2-of-7 code (21 possible codes of which 17 are used: 4 bits plus EoP <ce:cross-ref id="c0115" refid="b0120">[24]</ce:cross-ref>). To reduce the number of transitions a non-return-to-zero (NRZ) coding is used.</ce:para><ce:para id="p0310" view="all">Noise glitches on the inter-chip wires introduce extra transitions, potentially in both the forward and return paths; these must be detected and recovered from at each end of the link. The off-chip wiring is the most likely place for noise to be induced and it is assumed that such noise will cause a short glitch (<ce:italic>i.e. two</ce:italic> extra transitions) on a wire. Glitches will be reasonably uncommon, therefore data integrity is not addressed in hardware; detection of damaged packets can be delegated to system software if any recovery is to be attempted. The hardware simply has to keep running.</ce:para><ce:para id="p0315" view="all">The majority of the fault tolerance resides in the receiver (<ce:cross-ref id="c0305" refid="f0055">Fig. 11</ce:cross-ref><ce:float-anchor refid="f0055"/>) where various stages filter out potential problems.<ce:list id="l0025"><ce:list-item id="u0090"><ce:label>•</ce:label><ce:para id="p0530" view="all"><ce:italic>NRZ to RTZ Conversion</ce:italic>: The problem for the first stage of the receiver is that it may not know the <ce:italic>level</ce:italic> of an input wire at its reset time. This is overcome using a phase converter comprising two parallel RS flip-flops (<ce:cross-ref id="c0310" refid="f0060">Fig. 12</ce:cross-ref><ce:float-anchor refid="f0060"/>) which acts as a transition detector which is set by one <ce:italic>or more</ce:italic> input transitions. It is cleared locally between the detection of a symbol and its external acknowledgement. Two transitions are made per symbol. When <ce:italic>at least</ce:italic> two such phase converters are set, it is assumed that an input flit has been captured and passed to the next stage.</ce:para></ce:list-item><ce:list-item id="u0095"><ce:label>•</ce:label><ce:para id="p0535" view="all"><ce:italic>2-of-7 to 3-of-6 Conversion</ce:italic>: The flit is then searched by the symbol converter (<ce:cross-ref id="c0315" refid="f0065">Fig. 13</ce:cross-ref><ce:float-anchor refid="f0065"/>) using an asynchronous state machine with Muller C-elements <ce:cross-refs id="r0010" refid="b0125 b0130">[25,26]</ce:cross-refs>. In the absence of errors exactly one of these will be set but a glitch may have set more. The output is therefore filtered with a priority encoder based on mutual exclusion elements which chooses a single, legal, 'one-hot' code. There is no attempt to choose the 'correct' code - that information is not available - but <ce:italic>any</ce:italic> legal code will prevent a deadlock. It is then a simple matter to generate a 3-of-6 code with an auxiliary EoP line appropriate for the NoC.</ce:para></ce:list-item><ce:list-item id="u0100"><ce:label>•</ce:label><ce:para id="p0540" view="all"><ce:italic>Flit Counter</ce:italic>: Glitches can easily insert extra flits into a packet but it is important that no packet exceeds a maximum length. A flit counter is added to keep track of the number of flits and, if it exceeds a given threshold an extra EoP is inserted, notifying explicitly a framing error. The counter is reset on reception of an EoP.</ce:para></ce:list-item><ce:list-item id="u0105"><ce:label>•</ce:label><ce:para id="p0545" view="all"><ce:italic>Transmitter</ce:italic>: The only external input is the handshake acknowledge line. A phase converter detects at least one transition and treats that as the acknowledgement, further transitions being ignored until sending the next flit. When a transmitter is reset its state is 'ready to send'. Similarly, when a receiver is reset it sends an acknowledgement. If the reset occurred during reception this enables the transmitter to send again but if no acknowledgement was outstanding then there is a spurious transition which is filtered by the transmitter. The glitch tolerance automatically provides a simple, robust, single-ended reset capability which means that a node may be reset independently and still recover communication with its neighbours.</ce:para></ce:list-item></ce:list></ce:para><ce:section id="s0090" view="all"><ce:label>6.4.1</ce:label><ce:section-title id="st090">Performance assessment</ce:section-title><ce:para id="p0320" view="all">Our novel fault tolerant interface was compared with a conventional unit. Both circuits were simulated in Verilog handling roughly a million packets each in an extremely noisy environment in which packets have a 50% probability of being affected by a glitch. This noise level is exceedingly high and thus the number of packets corrupted should not be a concern. Results of these simulations are shown in <ce:cross-ref id="c0320" refid="t0010">Table 2</ce:cross-ref><ce:float-anchor refid="t0010"/>. <ce:italic>Glitches</ce:italic> represents the actual packet ratio affected by a glitch. <ce:italic>Error-free Packets</ce:italic> represents the percentage of the packets affected by a glitch that were interpreted correctly i.e., those that have resisted the glitch; <ce:italic>Deadlocks</ce:italic> represents the percentage of packets affected by a glitch that deadlocked the interface.</ce:para><ce:para id="p0325" view="all">As expected our design did not deadlock whereas a conventional unit deadlocked roughly 2% of the times that a glitch appears. This is very significant as a single deadlock has the potential to cripple a link <ce:italic>permanently</ce:italic> (until the whole system is rebooted). Given the communication-intensive application model supported by SpiNNaker this would mean a network becoming highly degraded very quickly if glitches appeared.</ce:para><ce:para id="p0330" view="all">The price of the deadlock-free interface is that glitches alter the received data roughly 10% more often. This is acceptable as glitches should be rare and erroneous packets can be detected and dropped.</ce:para></ce:section></ce:section><ce:section id="s0095" view="all"><ce:label>6.5</ce:label><ce:section-title id="st095">Intra-chip connections</ce:section-title><ce:para id="p0335" view="all">The asynchronous on-chip links are much less sensitive to noise-induced glitches, so they employ simpler logic. However the potential for deadlock with handshake communications still applies. To alleviate this intra-chip interfaces are provided with two levels of reset (soft and hard). Watchdog will apply soft reset first and if this does not solve the problem, it will perform a hard reset of the entire node, thus disrupting chip operation - but not deadlocking the on-chip network.</ce:para></ce:section></ce:section><ce:section id="s0100" view="all"><ce:label>7</ce:label><ce:section-title id="st100">Other fault-tolerant features</ce:section-title><ce:section id="s0105" view="all"><ce:label>7.1</ce:label><ce:section-title id="st105">Clock redundancy</ce:section-title><ce:para id="p0340" view="all">SpiNNaker chips have two independent PLLs with the intention of running the processors and the router at one frequency (200<ce:hsp sp="0.25"/>MHz) and the SDRAM at another (166<ce:hsp sp="0.25"/>MHz) to improve overall performance. However clock sources can be switched so, in the event of a PLL failure, all subsystems' clocks can be derived from the same source. This may reduce performance on that node but has no other consequence as the GALS interconnection is inherently adaptive.</ce:para></ce:section><ce:section id="s0110" view="all"><ce:label>7.2</ce:label><ce:section-title id="st110">GALS implications on fault tolerance</ce:section-title><ce:para id="p0345" view="all">Using a GALS approach not only facilitates the SoC design process but also simplifies isolation of faulty components in run time by supporting resetting or disabling on-chip components independently from the rest of the SoC.</ce:para></ce:section><ce:section id="s0115" view="all"><ce:label>7.3</ce:label><ce:section-title id="st115">Memory subsystem fault tolerance</ce:section-title><ce:para id="p0350" view="all">Various RAM is spread across a SpiNNaker chip (private TCMs, on-chip SRAM and off-chip RAM) which, as explained before, are the main expected points of failure.</ce:para><ce:para id="p0355" view="all">In principle it is possible to work-around hard failures in private memories but the degree of redundancy in the system means our plan is simply to inactivate cores with permanent TCM failure(s). The SDRAMs have some spare capacity and are mapped by the Monitor Processor so hard failures can be worked around.</ce:para><ce:para id="p0360" view="all">Soft errors present a different challenge. The SDRAM is usually accessed in blocks via DMA. The DMA controller includes a fully programmable CRC generator and checker so faulty blocks can be detected and subject to software recovery.</ce:para><ce:para id="p0365" view="all">Private memories are not protected by error detection; this was a pragmatic decision to maximise the speed and capacity of the chip. Soft errors in code space can cause a software crash resulting in some lost neural information. Recovery from this should be achieved by the watchdog mechanism resetting the affected core. Corruption of data space may be detected by software limit checks or crashing or other erratic behaviour. There may be some loss of data or some erroneous neural firing but the application should be robust enough to withstand this; it almost certainly happens in biological systems too!</ce:para></ce:section><ce:section id="s0120" view="all"><ce:label>7.4</ce:label><ce:section-title id="st120">Connecting with the outside world</ce:section-title><ce:para id="p0370" view="all">A SpiNNaker system communicates with a <ce:italic>host computer</ce:italic> via Ethernet (<ce:cross-ref id="c0325" refid="f0005">Fig. 1</ce:cross-ref>) using TCP/IP. This communication is used for different management actions, such as loading to the chip memories the application code or the neural connectivity information. Although all chips have an Ethernet interface in practice only a few will make use of it to reduce power consumption and maximize the computing resources available to neurons. Each Ethernet-connected chip translates frame-based communication to inter-chip packet-based communication. The presence of several possible interfaces does, however, eliminate another possible single-point failure.</ce:para></ce:section></ce:section><ce:section id="s0125" view="all"><ce:label>8</ce:label><ce:section-title id="st125">Related work</ce:section-title><ce:para id="p0375" view="all">Research in simulating biologically-plausible neural networks (brain-like systems) is not new. In the early 1990s a team at U.C.<ce:hsp sp="0.35"/>Berkeley worked on the Connectionist Network Supercomputer <ce:cross-ref id="c0120" refid="b0135">[27]</ce:cross-ref> which aimed to build a supercomputer specifically tailored for neural computation as a tool for connectionist research. The system was a 2D mesh, with a target size of 128 nodes (scalable to 512). Each node would incorporate a general-purpose RISC processor plus a vector coprocessor, 16 MBytes of RAM and a router. As far as we know, the node was built (under the codename T0), but the system never operated as a network. Experiments using up to five nodes in a bus configuration were discussed in <ce:cross-ref id="c0125" refid="b0140">[28]</ce:cross-ref>.</ce:para><ce:para id="p0380" view="all">More recently, the Microelectronics Division at the Technical University of Berlin worked on a project entitled <ce:italic>Design and implementation of spiking neural networks</ce:italic> [http://mikro.ee.tu-berlin.de/spinn] whose objectives are similar to those of SpiNNaker. A product of this is the Spiking Neural Network Emulation Engine (SEE), an acceleration board implemented with FPGAs interconnected via an on-board bus. SEE accelerators were able to perform neural computations 30 times faster than a desktop PC <ce:cross-ref id="c0130" refid="b0145">[29]</ce:cross-ref>. However, as these boards cannot be connected to form a network, they are not able to scale to the magnitudes of SpiNNaker.</ce:para><ce:para id="p0385" view="all">Research on spiking neural networks has also used different <ce:italic>off-the-shelf</ce:italic> technologies such as FPGAs <ce:cross-ref id="c0135" refid="b0150">[30]</ce:cross-ref>, graphic processors <ce:cross-ref id="c0140" refid="b0155">[31]</ce:cross-ref> and general purpose processors and accelerators <ce:cross-ref id="c0145" refid="b0160">[32]</ce:cross-ref>, obtaining speed-ups of over two orders of magnitude compared to software-only implementations.</ce:para><ce:para id="p0390" view="all">The relatively small scale of these systems allowed the assumption of a complete absence of component failures and, therefore, did not address reliability issues and did not incorporate fault-tolerant techniques.</ce:para><ce:para id="p0395" view="all">As far as we know, there are only three active projects comparable to SpiNNaker in terms of simulation scale. First, the Blue Brain project [http://bluebrain.epfl.ch/] aims to create <ce:italic>biologically accurate</ce:italic> functional models of the brain; however, model complexity (far more intricate than SpiNNaker's) only allows real-time execution of roughly a neuron per node <ce:cross-ref id="c0150" refid="b0165">[33]</ce:cross-ref>. This is a low figure in comparison with the several thousand (simpler) neurons per node supported by SpiNNaker.</ce:para><ce:para id="p0400" view="all">Secondly, DARPA's System of Neuromorphic Adaptive Plastic Scalable Electronics (SyNAPSE) project claims that it has achieved the simulation of spiking neural networks the size of a cat's brain <ce:cross-ref id="c0155" refid="b0170">[34]</ce:cross-ref> - <mml:math altimg="si16.gif" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> neurons - using Izhikevich models like those supported by SpiNNaker. However their simulations run 2-3 orders of magnitude slower than real-time.</ce:para><ce:para id="p0405" view="all">In contrast with the biologically-inspired SpiNNaker architecture, neither Blue Brain nor SyNAPSE contemplate the construction of a custom architecture but use general-purpose supercomputers from the IBM BlueGene family, depending on the underlying platform for their reliability and fault tolerance.</ce:para><ce:para id="p0410" view="all">The IBM BlueGene/L consists of 64<ce:hsp sp="0.25"/>K compute nodes, each based on PowerPC 400 processors. Additionally, it contains several service nodes that reside outside the core <ce:cross-ref id="c0160" refid="b0175">[35]</ce:cross-ref> and communicate with it using Ethernet. This infrastructure is used for booting, controlling and monitoring the system. System monitoring and job execution is done by the combined action of service and I/O nodes which maintain log files. During boot-up service nodes can control the computing core to the lowest level of granularity <ce:cross-ref id="c0165" refid="b0180">[36]</ce:cross-ref>. Service nodes can also directly write to and read from the device control registers of each processor. This feature is useful for handling runtime problems and investigating any booting up issues. For fault tolerance at boot-up or at run-time a self-test mechanism is kept in each chip to perform system diagnostics. The BlueGene supercomputer or others, <ce:italic>e.g.</ce:italic>, the Cray XT family of supercomputers <ce:cross-refs id="r0015" refid="b0185 b0190">[37,38]</ce:cross-refs>, being general-purpose will provide solutions that do not match the power-efficiency of SpiNNaker.</ce:para><ce:para id="p0415" view="all">Last but not least, the FACETS project <ce:cross-ref id="c0170" refid="b0195">[39]</ce:cross-ref> is attempting to create a faster than real-time hardware system for the simulation of networks of large but unspecified size. This architecture, while biologically inspired, uses a fixed synapse and neuron model and, therefore, is not a system as general as SpiNNaker. It employs <ce:italic>analogue</ce:italic> circuits to implement most of the central dynamic functions. For these blocks what would constitute a 'fault' is not precisely defined since analogue circuits exhibit a continuum of states. It is therefore relevant to discuss fault tolerance only with respect to the digital components: the communications infrastructure of the design. The FACETS architecture uses wafer-scale devices <ce:cross-ref id="c0175" refid="b0200">[40]</ce:cross-ref> to achieve the necessary connectivity. It uses AER signalling (similar to SpiNNaker), but with a circuit-switched, synchronous communications subsystem. Systems of this kind are fault tolerant in the sense of being reconfigurable in the event of a failed link; however they are not live-reroutable, thus the system provides no protection against transient faults nor does it permit packet recovery or retransmission while the system is active. A failed link requires at least a local reconfiguration with possible further routing impact. FACETS authors discuss fault tolerance but only as a general property of neural systems; the system does not include specifically designed fault-tolerant mechanisms. Thus the FACETS system, and its associated HICANN devices, once again represent a very different system designed to solve a different problem: faster than real-time neural simulation, for which power consumption is not a factor and fault tolerance merely a side effect rather than a design feature.</ce:para><ce:para id="p0420" view="all">Outside of the field of brain-like systems we can cite a heterogeneous SoC with certain architectural similarities to SpiNNaker <ce:cross-ref id="c0180" refid="b0205">[41]</ce:cross-ref>. This consists of an array of processors connected over an on-chip NoC and containing various heterogeneous system components. However, that project considers general-purpose applications within mission critical scenarios requiring the robustness of triple modular redundancy. This approach is an expensive solution unsuitable for SpiNNaker. In addition, their NoC appears to be a conventional synchronous design rather than the SpiNNaker self-timed communication fabric which may difficult scaling up the system.</ce:para><ce:para id="p0425" view="all">Reviewing the literature on general purpose multiprocessor systems we can see how memory fault tolerance efforts have been devoted mainly to the interconnect structure <ce:cross-ref id="c0185" refid="b0210">[42]</ce:cross-ref>, and to the use of ECC (originally following <ce:cross-ref id="c0190" refid="b0215">[43]</ce:cross-ref>), although this may not be in itself sufficient <ce:cross-ref id="c0195" refid="b0220">[44]</ce:cross-ref>. Given that symmetric redundancy of memory is expensive, recent work has introduced the concept of heterogeneous fault tolerance: graceful fall-back onto other components able to perform the same function, possibly with reduced performance <ce:cross-refs id="r0020" refid="b0225 b0230">[45,46]</ce:cross-refs>. Such an approach lowers overall hardware costs and represents a reasonable compromise in a power- or area-constrained design. Our asymmetric memory architecture follows this approach.</ce:para><ce:para id="p0430" view="all">Implementing fault tolerance in direct networks (such as 3D tori) is complex and costly and, therefore, a hot research topic. Current solutions are neither easy nor cheap to implement in silicon (see, for example, <ce:cross-refs id="r0025" refid="b0235 b0240">[47,48]</ce:cross-refs>). The simple emergency routing mechanism implemented in SpiNNker has been shown to be very effective for this purpose.</ce:para></ce:section><ce:section id="s0130" view="all"><ce:label>9</ce:label><ce:section-title id="st130">Summary and conclusions</ce:section-title><ce:para id="p0435" view="all">This paper has focused on introducing the broad collection of fault tolerance mechanisms implemented in SpiNNaker. Such features are quite extensive, and we have presented descriptions of the principal mechanisms and, where available, the pre-silicon assessment of their effectiveness. Some of the most important features discussed in this paper are the following:<ce:list id="l0030"><ce:list-item id="u0110"><ce:label>•</ce:label><ce:para id="p0550" view="all">A collection of system routines able to detect faults and to quickly recover from them when possible or to isolate components and to reconfigure the system otherwise.</ce:para></ce:list-item><ce:list-item id="u0115"><ce:label>•</ce:label><ce:para id="p0555" view="all">A range of application loading policies offering different levels of resilience and performance which can be used depending on the level of system degradation.</ce:para></ce:list-item><ce:list-item id="u0120"><ce:label>•</ce:label><ce:para id="p0560" view="all">The use of GALS logic that facilitates the SoC design process, simplifies timing closure and simplifies the isolation of faulty components but introduces weaknesses that have been overcome with custom-hardware.</ce:para></ce:list-item><ce:list-item id="u0125"><ce:label>•</ce:label><ce:para id="p0565" view="all">Asymmetric redundancy of the memory subsystem, granting graceful fall-back onto other components able to perform the same function although with reduced performance. Such an approach lowers overall hardware costs and represents a reasonable compromise in a power- or area-constrained design.</ce:para></ce:list-item><ce:list-item id="u0130"><ce:label>•</ce:label><ce:para id="p0570" view="all">A novel robust self-timed chip-to-chip interface circuit, resilient to noise-induced glitches preventing deadlocks.</ce:para></ce:list-item><ce:list-item id="u0135"><ce:label>•</ce:label><ce:para id="p0575" view="all">A stable communication fabric able to support communication demands exceeding those expected during regular operation.</ce:para></ce:list-item><ce:list-item id="u0140"><ce:label>•</ce:label><ce:para id="p0580" view="all">The novel emergency routing mechanism helps to deal with congestion and network failures.</ce:para></ce:list-item></ce:list></ce:para><ce:para id="p0440" view="all">The main conclusion of this paper is that SpiNNaker is a well-balanced fault-resilient architecture in which fault-tolerance has been considered a fundamental foundation of its design. This should facilitate its scaling from the prototype, 4-chip systems into practical, large-scale networks with over 1 million cores.</ce:para></ce:section></ce:sections><ce:acknowledgment id="ak005" view="all"><ce:section-title id="st145">Acknowledgements</ce:section-title><ce:para id="p0585" view="all">The SpiNNaker project is supported by the Engineering and Physical Sciences Research Council (EPSRC), through grants EP/G015740/1, EP/G013500/1, EP/D07908X/1 and GR/S61270/01, and also by industrial partners ARM and Silistix. Prof. Miguel-Alonso is supported by the Spanish Ministry of Science and Innovation (grant TIN2010-14931) and by the Basque Government (grant IT-242-07). Dr. Luján holds a Royal Society University Research Fellowship. Dr. Navaridas was a Royal Society Newton International Fellow when this research was performed.</ce:para></ce:acknowledgment></body><tail view="all"><ce:bibliography id="bi005" view="all"><ce:section-title id="st1000">References</ce:section-title><ce:bibliography-sec id="bs005" view="all"><ce:bib-reference id="b0005"><ce:label>[1]</ce:label><ce:other-ref id="j0005"><ce:textref>S. Davies, C. Patterson, F. Galluppi, A.D. Rast, D. Lester, S.B. Furber, Interfacing real-time spiking I/O with the SpiNNaker neuromimetic architecture, in: Proceedings 17th International Conference (ICONIP 2010), 2010.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0010"><ce:label>[2]</ce:label><sb:reference id="h0005"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Elliott</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Shadbolt</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Developmental robotics: Manifesto and application</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Philos. Trans. Royal Soc. A</sb:maintitle></sb:title></sb:series><sb:issue-nr>361</sb:issue-nr><sb:date>2003</sb:date></sb:issue><sb:pages><sb:first-page>2187</sb:first-page><sb:last-page>2206</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0015"><ce:label>[3]</ce:label><ce:other-ref id="j0010"><ce:textref>S. Herculano-Houzel, The human brain in numbers: a linearly scaled-up primate brain, Front Hum Neurosci. 3 (0). doi:10.3389/neuro.09.031.2009.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0020"><ce:label>[4]</ce:label><ce:other-ref id="j0015"><ce:textref>M. Nicolaidis, Soft Errors in Modern Electronic Systems, first ed., Springer, 2011.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0025"><ce:label>[5]</ce:label><sb:reference id="h0010"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Constantinescu</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Trends and challenges in VLSI circuit reliability</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Micro</sb:maintitle></sb:title><sb:volume-nr>23</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2003</sb:date></sb:issue><sb:pages><sb:first-page>14</sb:first-page><sb:last-page>19</sb:last-page></sb:pages><ce:doi>10.1109/MM.2003.1225959</ce:doi></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0030"><ce:label>[6]</ce:label><ce:other-ref id="j0020"><ce:textref>D.M. Chapiro, Globally-Asynchronous Locally-Synchronous Systems, Stanford University, CA, Ph.D. thesis, 1984.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0035"><ce:label>[7]</ce:label><sb:reference id="h0015"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>E.</ce:given-name><ce:surname>Izhikevich</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Simple model of spiking neurons</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Trans. Neural Networks</sb:maintitle></sb:title><sb:volume-nr>14</sb:volume-nr></sb:series><sb:date>2003</sb:date></sb:issue><sb:pages><sb:first-page>1569</sb:first-page><sb:last-page>1572</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0040"><ce:label>[8]</ce:label><ce:other-ref id="j0025"><ce:textref>C. Koch, I. Segev, Methods in Neuronal Modeling, The MIT Press, 1989.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0045"><ce:label>[9]</ce:label><sb:reference id="h0020"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.D.</ce:given-name><ce:surname>Rast</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Navaridas</ce:surname></sb:author><sb:author><ce:given-name>X.</ce:given-name><ce:surname>Jin</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Galluppi</ce:surname></sb:author><sb:author><ce:given-name>L.A.</ce:given-name><ce:surname>Plana</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Miguel-Alonso</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Patterson</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Lujan</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Furber</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Managing burstiness and scalability in event-driven models on the SpiNNaker neuromimetic system</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Int. J. Parallel Program</sb:maintitle></sb:title><sb:volume-nr>40</sb:volume-nr></sb:series><sb:issue-nr>6</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>553</sb:first-page><sb:last-page>582</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0050"><ce:label>[10]</ce:label><sb:reference id="h0025"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Rosenblatt</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:date>1962</sb:date><sb:publisher><sb:name>Spartan Books</sb:name><sb:location>Washington</sb:location></sb:publisher></sb:book></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0055"><ce:label>[11]</ce:label><ce:other-ref id="j0030"><ce:textref>P. Dayan, L.F. Abbott, Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems, The MIT Press, 2005.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0060"><ce:label>[12]</ce:label><sb:reference id="h0030"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Tiesinga</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Sejnowski</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Precision of pulse-coupled networks of integrate-and-fire neurons</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Network</sb:maintitle></sb:title><sb:volume-nr>12</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2001</sb:date></sb:issue><sb:pages><sb:first-page>215</sb:first-page><sb:last-page>233</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0065"><ce:label>[13]</ce:label><sb:reference id="h0035"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Brody</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Cell counts in cerebral cortex and brainstem</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Alzheimer Disease Senile Dementia and Related Disorders</sb:maintitle></sb:title></sb:series><sb:date>1978</sb:date></sb:issue><sb:pages><sb:first-page>345</sb:first-page><sb:last-page>351</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0070"><ce:label>[14]</ce:label><ce:other-ref id="j0035"><ce:textref>W. Maass, C.M. Bishop, Pulsed Neural Networks, The MIT Press, 1998.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0075"><ce:label>[15]</ce:label><ce:other-ref id="j0040"><ce:textref>M.A. Sivilotti, Wiring Considerations in Analog VLSI Systems, with Application to Field-Programmable Networks (VLSI), Ph.D. thesis, California Institute of Technology, Pasadena, CA, 1991.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0080"><ce:label>[16]</ce:label><ce:other-ref id="j0045"><ce:textref>M. Mahowald, VLSI Analogs of Neuronal Visual Processing: a Synthesis of Form and Function, Ph.D. dissertation, California Institute of Technology, Pasadena, CA, 1992.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0085"><ce:label>[17]</ce:label><ce:other-ref id="j0050"><ce:textref>M. Khan, A. Rast, J. Navaridas, X. Jin, L. Plana, M. Lujn, S. Temple, C. Patterson, D. Richards, J. Woods, J. Miguel-Alonso, S. Furber, Event-driven configuration of a neural network CMP system over an homogeneous interconnect fabric, Parallel Computing, in press, corrected proof.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0090"><ce:label>[18]</ce:label><ce:other-ref id="j0055"><ce:textref>W. J. Dally, B. Towles, Principles and Practices of Interconnection Networks, Morgan Kaufmann, 2004.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0095"><ce:label>[19]</ce:label><sb:reference id="h0040"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Navaridas</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Miguel-Alonso</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Pascual</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Ridruejo</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Simulating and evaluating interconnection networks with INSEE</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Simulation Modelling Practice and Theory</sb:maintitle></sb:title><sb:volume-nr>19</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2011</sb:date></sb:issue><sb:pages><sb:first-page>494</sb:first-page><sb:last-page>515</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0100"><ce:label>[20]</ce:label><ce:other-ref id="j0060"><ce:textref>M. Khan, D. Lester, L. Plana, A. Rast, X. Jin, E. Painkras, S. Furber, SpiNNaker: Mapping neural networks onto a massively-parallel chip multiprocessor, in: Proceedings of 2008 International Joint Conference on Neural Networks (IJCNN), 2008.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0105"><ce:label>[21]</ce:label><ce:other-ref id="j0065"><ce:textref>J. Navaridas, M. Luján, J. Miguel-Alonso, L. Plana, S. Furber, Understanding the interconnection network of SpiNNaker, in: Proceedings of 23rd International Conference on Supercomputing (ICS), 2009, pp. 286-295.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0110"><ce:label>[22]</ce:label><sb:reference id="h0045"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Verhoeff</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Delay-insensitive codes an overview</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Distrib. Comput.</sb:maintitle></sb:title><sb:volume-nr>3</sb:volume-nr></sb:series><sb:date>1988</sb:date></sb:issue><sb:pages><sb:first-page>1</sb:first-page><sb:last-page>8</sb:last-page></sb:pages><ce:doi>10.1007/BF01788562</ce:doi></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0115"><ce:label>[23]</ce:label><sb:reference id="h0050"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Bainbridge</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Furber</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>CHAIN: a delay-insensitive chip area interconnect</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Micro</sb:maintitle></sb:title><sb:volume-nr>22</sb:volume-nr></sb:series><sb:issue-nr>5</sb:issue-nr><sb:date>2002</sb:date></sb:issue><sb:pages><sb:first-page>16</sb:first-page><sb:last-page>23</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0120"><ce:label>[24]</ce:label><ce:other-ref id="j0070"><ce:textref>Y. Shi, S. Furber, J. Garside, L. Plana, Fault-tolerant delay insensitive inter-chip communication, in: Proceedings of 15th IEEE International Symposium on Asynchronous Circuits and Systems, 2009, pp. 77-84.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0125"><ce:label>[25]</ce:label><ce:other-ref id="j0075"><ce:textref>D.E. Muller, W. Bartky, A theory of asynchronous circuits, in: Proceedings of International Symposium Theory of Switching, Part 1, Harvard Univ. Press, 1959, pp. 204-243.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0130"><ce:label>[26]</ce:label><ce:other-ref id="j0080"><ce:textref>I. Sutherland, R. F. Sproull, D. Harris, Logical Effort, Morgan Kaufmann, 1999.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0135"><ce:label>[27]</ce:label><ce:other-ref id="j0085"><ce:textref>K. Asanovic, J. Beck, J. Feldman, N. Morgan, J. Wawrzynek, A supercomputer for neural computation, in: Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN), vol. 1, 1994, pp. 5-9.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0140"><ce:label>[28]</ce:label><ce:other-ref id="j0090"><ce:textref>P. Pfaerber, K. Asanovic, Parallel neural network training on MultiSpert, in: Proceedings of IEEE 3rd International Conference on Algorithms and Architectures for Parallel Processing (ICA3PP), 1997.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0145"><ce:label>[29]</ce:label><ce:other-ref id="j0095"><ce:textref>H. Hellmich, M. Geike, P. Griep, P. Mahr, M. Rafanelli, H. Klar, Emulation engine for spiking neurons and adaptive synaptic weights, in: Proceedings of IEEE International Joint Conference on Neural Networks (IJCNN), 2005.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0150"><ce:label>[30]</ce:label><ce:other-ref id="j0100"><ce:textref>M. Pearson, I. Gilhespy, K. Gurney, C. Melhuish, B. Mitchinson, M. Nibouche, A. Pipe, A real-time, FPGA based, biologically plausible neural network processor, in: Artificial Neural Networks: Formal Models and Their Applications ICANN 2005, vol. 3697 of Lecture Notes in Computer Science, Springer, Berlin/Heidelberg, 2005, pp. 755-756. doi:10.1007/11550907_161.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0155"><ce:label>[31]</ce:label><sb:reference id="h0055"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Han</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Taha</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Neuromorphic models on a GPGPU cluster, in: Neural Networks (IJCNN), The</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>International Joint Conference on</sb:maintitle></sb:title><sb:volume-nr>2010</sb:volume-nr></sb:series><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>1</sb:first-page><sb:last-page>8</sb:last-page></sb:pages><ce:doi>10.1109/IJCNN.2010.5596803</ce:doi></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0160"><ce:label>[32]</ce:label><sb:reference id="h0060"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Bhuiyan</ce:surname></sb:author><sb:author><ce:given-name>V.</ce:given-name><ce:surname>Pallipuram</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Smith</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Acceleration of spiking neural networks in emerging multi-core and GPU architectures, in: Parallel Distributed Processing, Workshops and PhD Forum (IPDPSW)</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE International Symposium on</sb:maintitle></sb:title><sb:volume-nr>2010</sb:volume-nr></sb:series><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>1</sb:first-page><sb:last-page>8</sb:last-page></sb:pages><ce:doi>10.1109/IPDPSW.2010.5470899</ce:doi></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0165"><ce:label>[33]</ce:label><sb:reference id="h0065"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Markram</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>The blue brain project</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Nature Reviews Neuroscience</sb:maintitle></sb:title><sb:volume-nr>7</sb:volume-nr></sb:series><sb:date>2006</sb:date></sb:issue><sb:pages><sb:first-page>153</sb:first-page><sb:last-page>160</sb:last-page></sb:pages><ce:doi>10.1038/nrn1848</ce:doi></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0170"><ce:label>[34]</ce:label><ce:other-ref id="j0105"><ce:textref>R. Ananthanarayanan, S.K. Esser, H.D. Simon, D.S. Modha, The cat is out of the bag: cortical simulations with <mml:math altimg="si17.gif" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> neurons, <mml:math altimg="si18.gif" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> synapses, in: Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis, SC '09, ACM, New York, NY, USA, 2009, pp. 63:1-63:12. doi:http://doi.acm.org/10.1145/1654059.1654124.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0175"><ce:label>[35]</ce:label><ce:other-ref id="j0110"><ce:textref>A. Gara, M.A. Blumrich, D. Chen, G.L.-T. Chiu, P. Coteus, M.E. Giampapa, R.A. Haring, P. Heidelberger, D. Hoenicke, G.V. Kopcsay, T.A. Liebsch, M. Ohmacht, B.D. Steinmacher-Burow, T. Takken, P. Vranas, Overview of the BlueGene/L system architecture, IBM J. Res. Develop. 49 (2.3) (2005) 195-212. doi:10.1147/rd.492.0195.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0180"><ce:label>[36]</ce:label><sb:reference id="h0070"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Haring</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Bellofatto</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Bright</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Crumley</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Dombrowa</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Douskey</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Ellavsky</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Gopalsamy</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Hoenicke</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Liebsch</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Marcella</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Ohmacht</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>BlueGene/L compute chip: Control, test and bring up intrastructure</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IBM Journal of Research and Development</sb:maintitle></sb:title><sb:volume-nr>49</sb:volume-nr></sb:series><sb:date>2005</sb:date></sb:issue><sb:pages><sb:first-page>289</sb:first-page><sb:last-page>301</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0185"><ce:label>[37]</ce:label><ce:other-ref id="j0115"><ce:textref>P. Worley, Comparison of Cray XT3 and XT4 Scalability, Cray Inc., May 2007.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0190"><ce:label>[38]</ce:label><ce:other-ref id="j0120"><ce:textref>A. Bland, J. Rogers, R. Kendall, D. Kothe, G. Shipman, Jaguar: The world's most powerful computer, in: Cray User Group 2009, Cray Inc., 2009.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0195"><ce:label>[39]</ce:label><ce:other-ref id="j0125"><ce:textref>J. Fieres, J. Schemmel, K. Meier, Realizing biological spiking neural network models in a configurable wafer-scale hardware system, in: Proceedings of 2008 International Joint Conference on Neural Networks (IJCNN), 2008, pp. 969-976.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0200"><ce:label>[40]</ce:label><ce:other-ref id="j0130"><ce:textref>J. Schemmel, J. Fieres, K. Meier, Wafer-scale integration of analog neural networks, in: Neural Networks, 2008. IJCNN 2008. (IEEE World Congress on Computational Intelligence). IEEE International Joint Conference on, 2008, pp. 431-438. doi:10.1109/IJCNN.2008.4633828.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0205"><ce:label>[41]</ce:label><sb:reference id="h0075"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Obermaisser</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Kraut</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Salloum</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A transient-resilient system-on-a-chip architecture with support for on-chip and off-chip TMR, in: Proc</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Seventh European Dependable Computing Conference (EDCC)</sb:maintitle></sb:title><sb:volume-nr>2008</sb:volume-nr></sb:series><sb:date>2008</sb:date></sb:issue><sb:pages><sb:first-page>123</sb:first-page><sb:last-page>134</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0210"><ce:label>[42]</ce:label><sb:reference id="h0080"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Mahmud</ce:surname></sb:author><sb:author><ce:given-name>L.T.</ce:given-name><ce:surname>Samaratunga</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Kommidi</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Fault-tolerant hierarchical networks for shared memory multiprocessors and their bandwidth analysis</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>The Computer Journal</sb:maintitle></sb:title><sb:volume-nr>45</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2002</sb:date></sb:issue><sb:pages><sb:first-page>147</sb:first-page><sb:last-page>161</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0215"><ce:label>[43]</ce:label><ce:other-ref id="j0135"><ce:textref>J. Yamada, T. Mano, J. Inoue, S. Nakajima, T. Matsuda, A submicron 1 Mbit dynamic RAM with a 4-bit-at-a-time built-in ECC circuit, IEEEJSSC SC-19 (5) (1984) 627-633.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0220"><ce:label>[44]</ce:label><sb:reference id="h0085"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Chen</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Somani</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Fault-containment in cache memories for TMR redundant processor systems</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Trans. Comput.</sb:maintitle></sb:title><sb:volume-nr>48</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>1999</sb:date></sb:issue><sb:pages><sb:first-page>386</sb:first-page><sb:last-page>397</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0225"><ce:label>[45]</ce:label><sb:reference id="h0090"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>I.</ce:given-name><ce:surname>Hong</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Potkonjak</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Karri</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A heterogeneous built-in self-repair approach using system-level synthesis flexibility</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Trans. Reliab.</sb:maintitle></sb:title><sb:volume-nr>53</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2004</sb:date></sb:issue><sb:pages><sb:first-page>93</sb:first-page><sb:last-page>101</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0230"><ce:label>[46]</ce:label><ce:other-ref id="j0140"><ce:textref>Y. Nakamura, K. Hiraki, Heterogeneous functional units for high speed fault-tolerant execution stage, in: Proceedings of 2007 13th Pacific Rim International Symposium on Dependable Computing, 2007, pp. 260-263.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="b0235"><ce:label>[47]</ce:label><sb:reference id="h0095"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Gomez</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Nordbotten</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Flich</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Lopez</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Robles</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Duato</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Skeie</ce:surname></sb:author><sb:author><ce:given-name>O.</ce:given-name><ce:surname>Lysne</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A routing methodology for achieving fault tolerance in direct networks</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Trans. Comput.</sb:maintitle></sb:title><sb:volume-nr>55</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2006</sb:date></sb:issue><sb:pages><sb:first-page>400</sb:first-page><sb:last-page>415</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="b0240"><ce:label>[48]</ce:label><sb:reference id="h0100"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>V.</ce:given-name><ce:surname>Puente</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Gregorio</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Immucube: Scalable fault-tolerant routing for k-ary n-cube networks</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Transactions on Parallel and Distributed Systems</sb:maintitle></sb:title><sb:volume-nr>18</sb:volume-nr></sb:series><sb:issue-nr>6</sb:issue-nr><sb:date>2007</sb:date></sb:issue><sb:pages><sb:first-page>776</sb:first-page><sb:last-page>788</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference></ce:bibliography-sec></ce:bibliography></tail></article></xocs:serial-item></xocs:doc>
